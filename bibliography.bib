@article{mcclean:2017,
	Author = {Jarrod McClean and Jonathan Romero and Ryan Babbush and Al{\'a}n Aspuru-Guzik},
	Journal = {New Journal of Physics},
	Title = {The Theory of Variational Hybrid Quantum-Classical Algorithms},
	Volume = {18},
	Year = 2016}

@article{boixo:2016,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160800263B},
	Archiveprefix = {arXiv},
	Author = {{Boixo}, S. and {Isakov}, S.~V. and {Smelyanskiy}, V.~N. and {Babbush}, R. and {Ding}, N. and {Jiang}, Z. and {Bremner}, M.~J. and {Martinis}, J.~M. and {Neven}, H.},
	Eprint = {1608.00263},
	Journal = {ArXiv e-prints},
	Keywords = {Quantum Physics},
	Month = jul,
	Primaryclass = {quant-ph},
	Title = {{Characterizing Quantum Supremacy in Near-Term Devices}},
	Year = 2016}

@article{mohseni:2017,
	Author = {Masoud Mohseni and Peter Read and Hartmut Neven and Sergio Boixo and Vasil Denchev and Ryan Babbush and Austin Fowler and Vadim Smelyanskiy and John Martinis},
	Journal = {Nature},
	Pages = {171--174},
	Title = {Commercialize Quantum Technologies in Five Years},
	Volume = {543},
	Year = 2017}

@article{balasubramanian:1997,
	Acmid = {250976},
	Address = {Cambridge, MA, USA},
	Author = {Balasubramanian, Vijay},
	Issue_Date = {Feb. 15, 1997},
	Journal = {Neural Comput.},
	Month = feb,
	Number = {2},
	Numpages = {20},
	Pages = {349--368},
	Publisher = {MIT Press},
	Title = {Statistical Inference, Occam's Razor, and Statistical Mechanics on the Space of Probability Distributions},
	Volume = {9},
	Year = {1997}}

@article{heckman:2013,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1305.3621H},
	Archiveprefix = {arXiv},
	Author = {{Heckman}, J.~J.},
	Eprint = {1305.3621},
	Journal = {ArXiv e-prints},
	Keywords = {High Energy Physics - Theory, Condensed Matter - Disordered Systems and Neural Networks, General Relativity and Quantum Cosmology},
	Month = may,
	Primaryclass = {hep-th},
	Title = {{Statistical Inference and String Theory}},
	Year = 2013}

@article{heckman:2016,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160506122H},
	Archiveprefix = {arXiv},
	Author = {{Heckman}, J.~J. and {Bernstein}, J.~G. and {Vigoda}, B.},
	Eprint = {1605.06122},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Computation, Condensed Matter - Disordered Systems and Neural Networks, High Energy Physics - Theory, Physics - Computational Physics},
	Month = may,
	Primaryclass = {stat.CO},
	Title = {{MCMC with Strings and Branes: The Suburban Algorithm}},
	Year = 2016}

@misc{kingma2017adam,
	Archiveprefix = {arXiv},
	Author = {Diederik P. Kingma and Jimmy Ba},
	Eprint = {1412.6980},
	Primaryclass = {cs.LG},
	Title = {Adam: A Method for Stochastic Optimization},
	Year = {2017}}

@article{friedrichs1944identity,
	Author = {Friedrichs, Kurt Otto},
	Journal = {Transactions of the American Mathematical Society},
	Number = {1},
	Pages = {132--151},
	Publisher = {JSTOR},
	Title = {The identity of weak and strong extensions of differential operators},
	Volume = {55},
	Year = {1944}}

@article{lerman2016algebra,
	Author = {Lerman, Eugene and Spivak, David I},
	Journal = {arXiv},
	Pages = {arXiv--1602},
	Title = {An algebra of open continuous time dynamical systems and networks},
	Year = {2016}}

@article{vagner2014algebras,
	Author = {Vagner, Dmitry and Spivak, David I and Lerman, Eugene},
	Journal = {arXiv preprint arXiv:1408.1598},
	Title = {Algebras of open dynamical systems on the operad of wiring diagrams},
	Year = {2014}}

@article{fong2016algebra,
	Author = {Fong, Brendan},
	Journal = {arXiv preprint arXiv:1609.05382},
	Title = {The algebra of open and interconnected systems},
	Year = {2016}}

@inproceedings{fong2016categorical,
	Author = {Fong, Brendan and Soboci{\'n}ski, Pawe{\l} and Rapisarda, Paolo},
	Booktitle = {Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in Computer Science},
	Pages = {495--504},
	Title = {A categorical approach to open and interconnected dynamical systems},
	Year = {2016}}

@article{zardini2020compositional,
	Author = {Zardini, Gioele and Spivak, David Isaac and Censi, Andrea and Frazzoli, Emilio},
	Journal = {arXiv preprint arXiv:2005.04715},
	Title = {A Compositional Sheaf-Theoretic Framework for Event-Based Systems},
	Year = {2020}}

@article{lerman2020networks,
	Author = {Lerman, Eugene and Schmidt, James},
	Journal = {Journal of Geometry and Physics},
	Pages = {103582},
	Publisher = {Elsevier},
	Title = {Networks of hybrid open systems},
	Volume = {149},
	Year = {2020}}

@inproceedings{fong2019backprop,
	Author = {Fong, Brendan and Spivak, David and Tuy{\'e}ras, R{\'e}my},
	Booktitle = {2019 34th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)},
	Organization = {IEEE},
	Pages = {1--13},
	Title = {Backprop as functor: A compositional perspective on supervised learning},
	Year = {2019}}

@misc{tensorflow2015-whitepaper,
	Author = {Mart\'{\i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and Andy~Davis and Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~Kudlur and Josh~Levenberg and Dandelion~Man\'{e} and Rajat~Monga and Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and Fernanda~Vi\'{e}gas and Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
	Note = {Software available from tensorflow.org},
	Title = {{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	Url = {https://www.tensorflow.org/},
	Year = {2015},
	Bdsk-Url-1 = {https://www.tensorflow.org/}}

@misc{billaudelle2020structural,
      title={Structural plasticity on an accelerated analog neuromorphic hardware system}, 
      author={Sebastian Billaudelle and Benjamin Cramer and Mihai A. Petrovici and Korbinian Schreiber and David Kappel and Johannes Schemmel and Karlheinz Meier},
      year={2020},
      eprint={1912.12047},
      archivePrefix={arXiv},
      primaryClass={q-bio.NC}
}

@article{kingma:2013,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1312.6114K},
	Archiveprefix = {arXiv},
	Author = {{Kingma}, D.~P and {Welling}, M.},
	Eprint = {1312.6114},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning, Computer Science - Learning},
	Month = dec,
	Primaryclass = {stat.ML},
	Title = {{Auto-Encoding Variational Bayes}},
	Year = 2013}

@article{rezende:2014,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1401.4082J},
	Archiveprefix = {arXiv},
	Author = {{Jimenez Rezende}, D. and {Mohamed}, S. and {Wierstra}, D.},
	Eprint = {1401.4082},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Learning, Statistics - Computation, Statistics - Methodology},
	Month = jan,
	Primaryclass = {stat.ML},
	Title = {{Stochastic Backpropagation and Approximate Inference in Deep Generative Models}},
	Year = 2014}

@article{rezende:2015,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150505770J},
	Archiveprefix = {arXiv},
	Author = {{Jimenez Rezende}, D. and {Mohamed}, S.},
	Eprint = {1505.05770},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Learning, Statistics - Computation, Statistics - Methodology},
	Month = may,
	Primaryclass = {stat.ML},
	Title = {{Variational Inference with Normalizing Flows}},
	Year = 2015}

@article{petro:2016,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Archiveprefix = {arXiv},
	Author = {{Petrovici}, M.~A. and {Bill}, J. and {Bytschok}, I. and {Schemmel}, J. and {Meier}, K.},
	Eid = {042312},
	Eprint = {1610.07161},
	Journal = {Phys. Rev. E},
	Month = oct,
	Number = 4,
	Pages = {042312},
	Title = {{Stochastic inference with spiking neurons in the high-conductance state}},
	Volume = 94,
	Year = 2016}

@misc{pytorchex:2020,
	Author = {Kai Arulkumaran and Xingdong Zuo and Soumith Chintala and Sam Gross and Reiji Hatsugai and Quan Vuong and Aziz Alto and Andrew Gambardella and Zeming Lin and Brandon Lin},
	Howpublished = {\url{https://github.com/pytorch/examples}},
	Journal = {GitHub repository},
	Publisher = {GitHub},
	Title = {PyTorch Examples},
	Year = {2020}}

@article{sharir:2020,
  title = {Deep Autoregressive Models for the Efficient Variational Simulation of Many-Body Quantum Systems},
  author = {Sharir, Or and Levine, Yoav and Wies, Noam and Carleo, Giuseppe and Shashua, Amnon},
  journal = {Phys. Rev. Lett.},
  volume = {124},
  issue = {2},
  pages = {020503},
  numpages = {6},
  year = {2020},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.124.020503},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.124.020503}
}

@article{ferminet,
  title={Ab-Initio Solution of the Many-Electron Schr{\"o}dinger Equation with Deep Neural Networks},
  author={D. Pfau and J.S. Spencer and A.G. de G. Matthews and W.M.C. Foulkes},
  journal={Phys. Rev. Research},
  year={2020},
  volume={2},
  issue = {3},
  pages={033429},
  doi = {10.1103/PhysRevResearch.2.033429},
  url = {https://link.aps.org/doi/10.1103/PhysRevResearch.2.033429}
}

@article{williams1992simple,
	Author = {Williams, Ronald J},
	Journal = {Machine learning},
	Number = {3-4},
	Pages = {229--256},
	Publisher = {Springer},
	Title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	Volume = {8},
	Year = {1992}}

@misc{czischek2020spiking,
      title={Spiking neuromorphic chip learns entangled quantum states}, 
      author={Stefanie Czischek and Andreas Baumbach and Sebastian Billaudelle and Benjamin Cramer and Lukas Kades and Jan M. Pawlowski and Markus K. Oberthaler and Johannes Schemmel and Mihai A. Petrovici and Thomas Gasenzer and Martin GÃ¤rttner},
      year={2020},
      eprint={2008.01039},
      archivePrefix={arXiv},
      primaryClass={cs.ET}
}
@misc{broughton2020tensorflow,
      title={TensorFlow Quantum: A Software Framework for Quantum Machine Learning}, 
      author={Michael Broughton and Guillaume Verdon and Trevor McCourt and Antonio J. Martinez and Jae Hyeon Yoo and Sergei V. Isakov and Philip Massey and Murphy Yuezhen Niu and Ramin Halavati and Evan Peters and Martin Leib and Andrea Skolik and Michael Streif and David Von Dollen and Jarrod R. McClean and Sergio Boixo and Dave Bacon and Alan K. Ho and Hartmut Neven and Masoud Mohseni},
      year={2020},
      eprint={2003.02989},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@aticle{carleo:2017,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017Sci...355..602C},
	Archiveprefix = {arXiv},
	Author = {{Carleo}, G. and {Troyer}, M.},
	Eprint = {1606.02318},
	Journal = {Science},
	Month = feb,
	Pages = {602-606},
	Primaryclass = {cond-mat.dis-nn},
	Title = {{Solving the quantum many-body problem with artificial neural networks}},
	Volume = 355,
	Year = 2017}

@article{hochreiter1997long,
	Author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	Journal = {Neural computation},
	Number = {8},
	Pages = {1735--1780},
	Publisher = {MIT Press},
	Title = {Long short-term memory},
	Volume = {9},
	Year = {1997}}

@article{williams1989learning,
	Author = {Williams, Ronald J and Zipser, David},
	Journal = {Neural computation},
	Number = {2},
	Pages = {270--280},
	Publisher = {MIT Press},
	Title = {A learning algorithm for continually running fully recurrent neural networks},
	Volume = {1},
	Year = {1989}}

@book{robinson1987utility,
	Author = {Robinson, AJ and Fallside, Frank},
	Publisher = {University of Cambridge Department of Engineering Cambridge, MA},
	Title = {The utility driven dynamic error propagation network},
	Year = {1987}}

@article{gers2002learning,
	Author = {Gers, Felix A and Schraudolph, Nicol N and Schmidhuber, J{\"u}rgen},
	Journal = {Journal of machine learning research},
	Number = {Aug},
	Pages = {115--143},
	Title = {Learning precise timing with LSTM recurrent networks},
	Volume = {3},
	Year = {2002}}

@article{crick1989recent,
	Author = {Crick, Francis},
	Journal = {Nature},
	Number = {6203},
	Pages = {129--132},
	Publisher = {Springer},
	Title = {The recent excitement about neural networks},
	Volume = {337},
	Year = {1989}}

@inproceedings{akrout2019deep,
	Author = {Akrout, Mohamed and Wilson, Collin and Humphreys, Peter and Lillicrap, Timothy and Tweed, Douglas B},
	Booktitle = {Advances in neural information processing systems},
	Pages = {976--984},
	Title = {Deep learning without weight transport},
	Year = {2019}}

@article{grossberg1987competitive,
	Author = {Grossberg, Stephen},
	Journal = {Cognitive science},
	Number = {1},
	Pages = {23--63},
	Publisher = {Elsevier},
	Title = {Competitive learning: From interactive activation to adaptive resonance},
	Volume = {11},
	Year = {1987}}

@article{schemmel:2010,
	Author = {Schemmel, J. and Br\"uderle, D. and Gr\"ubl, A. and Hock, M. and Meier, K. and Millner, S.},
	Journal = {Proceedings of the 2010 IEEE International Symposium on Circuits	and Systems (ISCAS"10)},
	Pages = {1947--1950},
	Title = {A Wafer-Scale Neuromorphic Hardware System for Large-Scale Neural Modeling},
	Year = {2010}}

@article{guedes2019axonal,
	Author = {Guedes-Dias, Pedro and Holzbaur, Erika LF},
	Journal = {Science},
	Number = {6462},
	Pages = {eaaw9997},
	Publisher = {American Association for the Advancement of Science},
	Title = {Axonal transport: Driving synaptic function},
	Volume = {366},
	Year = {2019}}

@inbook{Ohno-Shosaku:2009,
	Address = {Berlin, Heidelberg},
	Author = {Ohno-Shosaku, Takako},
	Booktitle = {Encyclopedia of Neuroscience},
	Doi = {10.1007/978-3-540-29678-2_5123},
	Editor = {Binder, Marc D. and Hirokawa, Nobutaka and Windhorst, Uwe},
	Isbn = {978-3-540-29678-2},
	Pages = {3529--3533},
	Publisher = {Springer Berlin Heidelberg},
	Title = {Retrograde Messenger},
	Url = {https://doi.org/10.1007/978-3-540-29678-2_5123},
	Year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-540-29678-2_5123}}

@article{rolfe:2016,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160902200R},
	Archiveprefix = {arXiv},
	Author = {{Rolfe}, J.~T.},
	Eprint = {1609.02200},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning, Computer Science - Learning},
	Month = sep,
	Primaryclass = {stat.ML},
	Title = {{Discrete Variational Autoencoders}},
	Year = 2016}

@book{watanabe:2009,
	Author = {Watanabe, S.},
	Publisher = {Cambridge University Press},
	Series = {Cambridge Monographs on Applied and Computational Mathematics},
	Title = {Algebraic Geometry and Statistical Learning Theory},
	Year = {2009}}

@article{choromanska:2014,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1412.0233C},
	Archiveprefix = {arXiv},
	Author = {{Choromanska}, A. and {Henaff}, M. and {Mathieu}, M. and {Ben Arous}, G. and {LeCun}, Y.},
	Eprint = {1412.0233},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning},
	Month = nov,
	Primaryclass = {cs.LG},
	Title = {{The Loss Surfaces of Multilayer Networks}},
	Year = 2014}

@article{spivak:2013,
	Archiveprefix = {arXiv},
	Author = {David I. Spivak},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1305-0297},
	Eprint = {1305.0297},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:46:32 +0200},
	Title = {The operad of wiring diagrams: formalizing a graphical language for databases, recursion, and plug-and-play circuits},
	Url = {http://arxiv.org/abs/1305.0297},
	Volume = {abs/1305.0297},
	Year = {2013},
	Bdsk-Url-1 = {http://arxiv.org/abs/1305.0297}}

@article{wetterich2019quantum,
	Author = {Wetterich, Christof},
	Journal = {Nuclear Physics B},
	Pages = {114776},
	Publisher = {Elsevier},
	Title = {Quantum computing with classical bits},
	Volume = {948},
	Year = {2019}}

@book{guillemin:1994,
	Author = {Guillemin, Victor},
	Title = {{Moment maps and combinatorial invariants of Hamiltonian $T^n$ spaces}},
	Year = {1994}}

@article{delzant:1988,
	Author = {Delzant, T.},
	Journal = {Bulletin Societe Mathematique France},
	Title = {{Hamiltoniens periodiques et image convex de l'application moment}},
	Year = {1988}}

@draft{heckman:2016jud,
	Author = {Heckman, Jonathan J. and Bernstein, Jeffrey G. and Vigoda, Ben},
	Title = {{MCMC with Strings and Branes: The Suburban Algorithm}},
	Year = {2016}}

@article{galan:1999,
	Abstract = {The general equations for the parametric sensitivity functions of a broad class of hybrid discrete/continuous dynamic systems where the continuous part is described by differential--algebraic equations (DAEs) are presented. For the cases where this continuous part is an ordinary differential equation system (ODEs) or a linear time invariant DAE, sufficient conditions for the existence and uniqueness of the sensitivity functions are derived. Numerical computation of these sensitivity functions has been implemented as a generic functionality in a mathematical modeling environment. Special cases and application examples are used for illustration.},
	Author = {Santos Gal{\'a}n and William F. Feehery and Paul I. Barton},
	Doi = {https://doi.org/10.1016/S0168-9274(98)00125-1},
	Issn = {0168-9274},
	Journal = {Applied Numerical Mathematics},
	Keywords = {Hybrid systems, Parametric sensitivities, Existence and uniqueness, Differential--algebraic equations},
	Number = {1},
	Pages = {17 - 47},
	Title = {Parametric sensitivity functions for hybrid discrete/continuous systems},
	Url = {http://www.sciencedirect.com/science/article/pii/S0168927498001251},
	Volume = {31},
	Year = {1999}}

@draft{segal:2004,
	Author = {Segal, Graeme},
	Title = {{The definition of conformal field theory}},
	Year = {2004}}

@draft{segal:2011,
	Author = {Segal, Graeme},
	Title = {{Three roles of quantum field theory}},
	Year = {2011}}

@draft{baez:2009,
	Author = {Baez, John C. and Lauda, Aaron},
	Title = {{A Prehistory of n-Categorical Physics}},
	Year = {2009}}

@draft{gromov:2013,
	Author = {Misha Gromov},
	Title = {{In a Search for a Structure, Part 1: Entropy}},
	Year = {2013}}

@draft{bennequin:2014,
	Author = {Daniel Bennequin},
	Title = {{Topological forms of information}},
	Year = {2014}}

@draft{bengio:2016,
	Author = {{Yoshua Bengio, Dong-Hyun Lee, Jorg Bornschein, Thomas Mesnard and Zhouhan Lin}},
	Title = {{Towards Biologically Plausible Deep Learning}},
	Year = {2016}}

@draft{witten:2010,
	Author = {Witten, Edward},
	Title = {{A New Look At The Path Integral Of Quantum Mechanics}},
	Year = {2010}}

@draft{poplavskii:1975,
	Author = {R.P. Poplavskii},
	Title = {{Thermodynamical models of information processing (in Russian)}},
	Year = {1975}}

@draft{manin:2009a,
	Author = {Yuri I. Manin},
	Title = {{Renormalization and Computation I: Motivation and Background}},
	Year = {2009}}

@draft{manin:2009b,
	Author = {Yuri I. Manin},
	Title = {{Renormalization and Computation II: Time Cut-Off and the Halting-Problem}},
	Year = {2009}}

@draft{baez:2011,
	Author = {J. Baez and M. Stay},
	Title = {{Physics, Topology, Logic and Computation: A Rosetta Stone}},
	Year = {2011}}

@draft{petrovici:2013,
	Author = {{Mihai A. Petrovici, Johannes Bill, Ilja Bytschok, Johannes Schemmel and Karlheinz Meier}},
	Title = {{Stochastic inference with deterministic spiking neurons}},
	Year = {2013}}

@draft{kappel:2015,
	Author = {{David Kappel, Stefan Habenschuss , Robert Legenstein, Wolfgang Maass}},
	Title = {{Network Plasticity as Bayesian Inference}},
	Year = {2015}}

@book{absil:2008,
	Author = {{P.-A. Absil, R. Mahony, R. Sepulchre}},
	Publisher = {Princeton U. Press},
	Title = {{Optimization algorithms on matrix manifolds}},
	Year = {2008}}

@book{ibilisco:2009,
	Author = {{Paolo Gibilisco, Eva Riccomagno, Maria Piera Rogantin and Henry P. Wynn}},
	Publisher = {Cambridge U. Press},
	Title = {{Algebraic and Geometric Methods in Statistics}},
	Year = {2009}}

@article{aughlin:1998,
	Author = {{Simon B. Laughlin, Rob R. de Ruyter van Steveninck2 and John C. Anderson}},
	Journal = {Nature},
	Title = {{The metabolic cost of neural information}},
	Year = {1998}}

@article{schulman:2015,
	Archiveprefix = {arXiv},
	Author = {John Schulman and Nicolas Heess and Theophane Weber and Pieter Abbeel},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/SchulmanHWA15},
	Eprint = {1506.05254},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:47:46 +0200},
	Title = {Gradient Estimation Using Stochastic Computation Graphs},
	Url = {http://arxiv.org/abs/1506.05254},
	Volume = {abs/1506.05254},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1506.05254}}

@article{theodorou2010generalized,
	Author = {Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
	Journal = {The Journal of Machine Learning Research},
	Pages = {3137--3181},
	Publisher = {JMLR. org},
	Title = {A generalized path integral control approach to reinforcement learning},
	Volume = {11},
	Year = {2010}}

@article{kappen2005path,
	Author = {Kappen, Hilbert J},
	Journal = {Journal of statistical mechanics: theory and experiment},
	Number = {11},
	Pages = {P11011},
	Publisher = {IOP Publishing},
	Title = {Path integrals and symmetry breaking for optimal control theory},
	Volume = {2005},
	Year = {2005}}

@article{kappen2005linear,
	Author = {Kappen, Hilbert J},
	Journal = {Physical review letters},
	Number = {20},
	Pages = {200201},
	Publisher = {APS},
	Title = {Linear theory for control of nonlinear stochastic systems},
	Volume = {95},
	Year = {2005}}

@article{kappen2008stochastic,
	Author = {Kappen, HJ},
	Journal = {ICML, Helsinki, Radbound University, Nijmegen, Netherlands},
	Title = {Stochastic optimal control theory},
	Year = {2008}}

@misc{koopman:lfsr,
  title = {Maximal Length LFSR Feedback Terms},
  author = {Koopman, Philip},
  howpublished = {\url{http://users.ece.cmu.edu/~koopman/lfsr/index.html}},
  note = {Accessed: 2020-09-30}
}

@article{bellec2020solution,
	Abstract = {Recurrently connected networks of spiking neurons underlie the astounding information processing capabilities of the brain. Yet in spite of extensive research, how they can learn through synaptic plasticity to carry out complex network computations remains unclear. We argue that two pieces of this puzzle were provided by experimental data from neuroscience. A mathematical result tells us how these pieces need to be combined to enable biologically plausible online network learning through gradient descent, in particular deep reinforcement learning. This learning method--called e-prop--approaches the performance of backpropagation through time (BPTT), the best-known method for training recurrent neural networks in machine learning. In addition, it suggests a method for powerful on-chip learning in energy-efficient spike-based hardware for artificial intelligence.},
	Author = {Bellec, Guillaume and Scherr, Franz and Subramoney, Anand and Hajek, Elias and Salaj, Darjan and Legenstein, Robert and Maass, Wolfgang},
	Id = {Bellec2020},
	Isbn = {2041-1723},
	Journal = {Nature Communications},
	Number = {1},
	Pages = {3625},
	Title = {A solution to the learning dilemma for recurrent networks of spiking neurons},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41467-020-17236-y},
	Volume = {11},
	Year = {2020}}

@book{achter:2005,
	Author = {{Lior Pachter, Bernd Sturmfels}},
	Publisher = {Cambridge U. Press},
	Title = {{Algebraic Statistics for Computational Biology}},
	Year = {2005}}

@article{mnih:2014,
	Author = {Andriy Mnih and Karol Gregor},
	Journal = {CoRR},
	Title = {Neural Variational Inference and Learning in Belief Networks},
	Volume = {abs/1402.0030},
	Year = {2014}}

@article{gomez:2018,
	Author = {Gomez-Bombarelli, Rafael and Wei, Jennifer N. and Duvenaud, David and Hernandez-Lobato, Jose Miguel and Sanchez-Lengeling, Benjami-n and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D. and Adams, Ryan P. and Aspuru-Guzik, Alan},
	Doi = {10.1021/acscentsci.7b00572},
	Eprint = {https://doi.org/10.1021/acscentsci.7b00572},
	Journal = {ACS Central Science},
	Number = {2},
	Pages = {268-276},
	Title = {Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules},
	Url = {https://doi.org/10.1021/acscentsci.7b00572},
	Volume = {4},
	Year = {2018}}

@inbook{selinger:2011,
	Abstract = {This article is intended as a reference guide to various notions of monoidal categories and their associated string diagrams. It is hoped that this will be useful not just to mathematicians, but also to physicists, computer scientists, and others who use diagrammatic reasoning. We have opted for a somewhat informal treatment of topological notions, and have omitted most proofs. Nevertheless, the exposition is sufficiently detailed to make it clear what is presently known, and to serve as a starting place for more in-depth study. Where possible, we provide pointers to more rigorous treatments in the literature. Where we include results that have only been proved in special cases, we indicate this in the form of caveats.},
	Address = {Berlin, Heidelberg},
	Author = {Selinger, P.},
	Booktitle = {New Structures for Physics},
	Doi = {10.1007/978-3-642-12821-9_4},
	Editor = {Coecke, Bob},
	Isbn = {978-3-642-12821-9},
	Pages = {289--355},
	Publisher = {Springer Berlin Heidelberg},
	Title = {A Survey of Graphical Languages for Monoidal Categories},
	Url = {https://doi.org/10.1007/978-3-642-12821-9_4},
	Year = {2011}}

@article{mcculloch1943logical,
	Author = {McCulloch, Warren S and Pitts, Walter},
	Journal = {The bulletin of mathematical biophysics},
	Number = {4},
	Pages = {115--133},
	Publisher = {Springer},
	Title = {A logical calculus of the ideas immanent in nervous activity},
	Volume = {5},
	Year = {1943}}

@article{vonneumann1956probabilistic,
	Author = {Von Neumann, John},
	Journal = {Automata studies},
	Pages = {43--98},
	Title = {Probabilistic logics and the synthesis of reliable organisms from unreliable components},
	Volume = {34},
	Year = {1956}}

@article{turing:1950,
	Author = {Turing, AM},
	Title = {Computing Machinery and Intelligence},
	Year = {1950}}

@article{article,
	Author = {Author1 LastName1 and Author2 LastName2 and Author3 LastName3},
	Doi = {10.3389/fnins.2013.12345},
	Journal = {Frontiers in Neuroscience},
	Number = {30},
	Pages = {10127-10134},
	Title = {Article Title},
	Url = {http://www.frontiersin.org/Journal/10.3389/fnins.2013.12345/abstract},
	Volume = {30},
	Year = {2013}}

@book{book,
	Address = {The city},
	Author = {Author Name},
	Publisher = {The name of the publisher},
	Title = {The title of the work},
	Year = 1993}

@inproceedings{schemmel2017accelerated,
	Author = {Schemmel, Johannes and Kriener, Laura and M{\"u}ller, Paul and Meier, Karlheinz},
	Booktitle = {2017 International Joint Conference on Neural Networks (IJCNN)},
	Organization = {IEEE},
	Pages = {2217--2226},
	Title = {An accelerated analog neuromorphic hardware system emulating NMDA-and calcium-based non-linear dendrites},
	Year = {2017}}

@incollection{connes1999hopf,
	Author = {Connes, Alain and Kreimer, Dirk},
	Booktitle = {Quantum field theory: perspective and prospective},
	Pages = {59--109},
	Publisher = {Springer},
	Title = {Hopf algebras, renormalization and noncommutative geometry},
	Year = {1999}}

@article{baez2011prehistory,
	Author = {Baez, John C and Lauda, Aaron},
	Journal = {Deep Beauty: Understanding the Quantum World Through Mathematical Innovation},
	Pages = {13--128},
	Publisher = {Cambridge University Press Cambridge, UK},
	Title = {A prehistory of n-categorical physics},
	Year = {2011}}

@article{feynman1949space,
	Author = {Feynman, Richard Phillips},
	Journal = {Physical Review},
	Number = {6},
	Pages = {769},
	Publisher = {APS},
	Title = {Space-time approach to quantum electrodynamics},
	Volume = {76},
	Year = {1949}}

@incollection{chapter,
	Address = {The city},
	Author = {Bauthor Surname},
	Booktitle = {The title of the book},
	Editor = {Editor Name},
	Pages = {201-213},
	Publisher = {The name of the publisher},
	Title = {The title of the work},
	Year = 2002}

@misc{cramer2020training,
	Archiveprefix = {arXiv},
	Author = {Benjamin Cramer and Sebastian Billaudelle and Simeon Kanya and Aron Leibfried and Andreas Gr{\"u}bl and Vitali Karasenko and Christian Pehle and Korbinian Schreiber and Yannik Stradmann and Johannes Weis and Johannes Schemmel and Friedemann Zenke},
	Eprint = {2006.07239},
	Primaryclass = {cs.NE},
	Title = {Training spiking multi-layer networks with surrogate gradients on an analog neuromorphic substrate},
	Year = {2020}}

@article{rupel:2013,
	Author = {Rupel, Dylan and Spivak, David I},
	Journal = {arXiv preprint arXiv:1307.6894},
	Title = {The operad of temporal wiring diagrams: formalizing a graphical language for discrete-time processes},
	Year = {2013}}

@article{wunderlich2019demonstrating,
	Author = {Wunderlich, Timo and Kungl, Akos F and M{\"u}ller, Eric and Hartel, Andreas and Stradmann, Yannik and Aamir, Syed Ahmed and Gr{\"u}bl, Andreas and Heimbrecht, Arthur and Schreiber, Korbinian and St{\"o}ckel, David and others},
	Journal = {Frontiers in neuroscience},
	Pages = {260},
	Publisher = {Frontiers},
	Title = {Demonstrating advantages of neuromorphic computation: a pilot study},
	Volume = {13},
	Year = {2019}}

@misc{krizhevsky2009learning,
	Author = {Krizhevsky, Alex and Hinton, Geoffrey and others},
	Title = {Learning multiple layers of features from tiny images},
	Year = {2009}}

@article{gutig2016spiking,
  title={Spiking neurons can discover predictive features by aggregate-label learning},
  author={G{\"u}tig, Robert},
  journal={Science},
  volume={351},
  number={6277},
  year={2016},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{lambek:1985,
	Author = {Lambek, Joachim},
	Doi = {10.1007/3-540-17184-3_44},
	Month = {05},
	Pages = {136-175},
	Title = {Cartesian Closed Categories and Typed Lambda-calculi.},
	Year = {1985}}

@incollection{baez:2010,
	Author = {Baez, John and Stay, Mike},
	Booktitle = {New structures for physics},
	Pages = {95--172},
	Publisher = {Springer},
	Title = {Physics, topology, logic and computation: a Rosetta Stone},
	Year = {2010}}

@article{UVM:2017,
	Doi = {10.1109/IEEESTD.2017.7932212},
	Journal = {IEEE Std 1800.2-2017},
	Pages = {1-472},
	Title = {IEEE Standard for Universal Verification Methodology Language Reference Manual},
	Year = {2017}}

@phdtheis{karasenko:2020,
	Author = {Karasenko, Vitali},
	School = {PhD thesis, Heidelberg University},
	Title = {Von Neumann bottlenecks in non-von Neumann computing architectures},
	Year = {2020}}

@inproceedings{conference,
	Author = {Cauthor Name and Dauthor Surname and Fauthor LastName},
	Booktitle = {The title of the conference proceedings},
	Editor = {Editor Name1 and Editor Name2},
	Pages = {41-50},
	Publisher = {The name of the publisher},
	Title = {The title of the work},
	Year = 1996}

@book{cho,
	Address = {Patent Country},
	Author = {Gauthor Name1},
	Publisher = {Country code and patent number},
	Title = {The title of the work},
	Year = 2013}

@book{patent,
	Address = {Patent country},
	Author = {Hauthor Surname1},
	Publisher = {Patent number},
	Title = {The title of the work},
	Year = 2010}

@misc{dataset,
	Author = {Author1 LastName1 and Author2 LastName2 and Author3 LastName3},
	Doi = {10.000/55555},
	Title = {Data Title},
	Url = {http://www.frontiersin.org/},
	Year = {2011}}

@article{bohnstingl2019neuromorphic,
	Author = {Bohnstingl, Thomas and Scherr, Franz and Pehle, Christian and Meier, Karlheinz and Maass, Wolfgang},
	Journal = {Frontiers in neuroscience},
	Pages = {483},
	Publisher = {Frontiers},
	Title = {Neuromorphic hardware learns to learn},
	Volume = {13},
	Year = {2019}}

@article{schreiber2020closed,
	Author = {Schreiber, K and Wunderlich, TC and Pehle, C and Petrovici, MA and Schemmel, J and Meier, K},
	Journal = {arXiv preprint arXiv:2004.14829},
	Title = {Closed-loop experiments on the BrainScaleS-2 architecture},
	Year = {2020}}

@article{bengio:2015,
	Archiveprefix = {arXiv},
	Author = {Yoshua Bengio and Dong{-}Hyun Lee and J{\"{o}}rg Bornschein and Zhouhan Lin},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/BengioLBL15},
	Eprint = {1502.04156},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:46:59 +0200},
	Title = {Towards Biologically Plausible Deep Learning},
	Url = {http://arxiv.org/abs/1502.04156},
	Volume = {abs/1502.04156},
	Year = {2015}}

@article{schmidhuber:2015,
	Author = {Schmidhuber, J{\"u}rgen},
	Journal = {Neural networks},
	Pages = {85--117},
	Publisher = {Elsevier},
	Title = {Deep learning in neural networks: An overview},
	Volume = {61},
	Year = {2015}}

@inproceedings{schmitt:2017,
	Author = {Schmitt, Sebastian and Kl{\"a}hn, Johann and Bellec, Guillaume and Gr{\"u}bl, Andreas and Guettler, Maurice and Hartel, Andreas and Hartmann, Stephan and Husmann, Dan and Husmann, Kai and Jeltsch, Sebastian and others},
	Booktitle = {2017 International Joint Conference on Neural Networks (IJCNN)},
	Organization = {IEEE},
	Pages = {2227--2234},
	Title = {Neuromorphic hardware in the loop: Training a deep spiking network on the brainscales wafer-scale system},
	Year = {2017}}

@article{furber:2014,
	Author = {Furber, Steve B and Galluppi, Francesco and Temple, Steve and Plana, Luis A},
	Journal = {Proceedings of the IEEE},
	Number = {5},
	Pages = {652--665},
	Publisher = {IEEE},
	Title = {The spinnaker project},
	Volume = {102},
	Year = {2014}}

@article {Zenke2020.06.29.176925,
	author = {Zenke, Friedemann and Vogels, Tim P.},
	title = {The remarkable robustness of surrogate gradient learning for instilling complex function in spiking neural networks},
	elocation-id = {2020.06.29.176925},
	year = {2020},
	doi = {10.1101/2020.06.29.176925},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Brains process information in spiking neural networks. Their intricate connections shape the diverse functions these networks perform. In comparison, the functional capabilities of models of spiking networks are still rudimentary. This shortcoming is mainly due to the lack of insight and practical algorithms to construct the necessary connectivity. Any such algorithm typically attempts to build networks by iteratively reducing the error compared to a desired output. But assigning credit to hidden units in multi-layered spiking networks has remained challenging due to the non-differentiable nonlinearity of spikes. To avoid this issue, one can employ surrogate gradients to discover the required connectivity in spiking network models. However, the choice of a surrogate is not unique, raising the question of how its implementation influences the effectiveness of the method. Here, we use numerical simulations to systematically study how essential design parameters of surrogate gradients impact learning performance on a range of classification problems. We show that surrogate gradient learning is robust to different shapes of underlying surrogate derivatives, but the choice of the derivative{\textquoteright}s scale can substantially affect learning performance. When we combine surrogate gradients with a suitable activity regularization technique, robust information processing can be achieved in spiking networks even at the sparse activity limit. Our study provides a systematic account of the remarkable robustness of surrogate gradient learning and serves as a practical guide to model functional spiking neural networks.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/06/29/2020.06.29.176925},
	eprint = {https://www.biorxiv.org/content/early/2020/06/29/2020.06.29.176925.full.pdf},
	journal = {bioRxiv}
}


@article{benjamin:2014,
	Author = {Benjamin, Ben Varkey and Gao, Peiran and McQuinn, Emmett and Choudhary, Swadesh and Chandrasekaran, Anand R and Bussat, Jean-Marie and Alvarez-Icaza, Rodrigo and Arthur, John V and Merolla, Paul A and Boahen, Kwabena},
	Journal = {Proceedings of the IEEE},
	Number = {5},
	Pages = {699--716},
	Publisher = {IEEE},
	Title = {Neurogrid: A mixed-analog-digital multichip system for large-scale neural simulations},
	Volume = {102},
	Year = {2014}}

@inproceedings{esser:2015backpropagation,
	Author = {Esser, Steve K and Appuswamy, Rathinakumar and Merolla, Paul and Arthur, John V and Modha, Dharmendra S},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {1117--1125},
	Title = {Backpropagation for energy-efficient neuromorphic computing},
	Year = {2015}}

@article{rackauckas2018comparison,
	Author = {Rackauckas, Christopher and Ma, Yingbo and Dixit, Vaibhav and Guo, Xingjian and Innes, Mike and Revels, Jarrett and Nyberg, Joakim and Ivaturi, Vijay},
	Journal = {arXiv preprint arXiv:1812.01892},
	Title = {A comparison of automatic differentiation and continuous sensitivity analysis for derivatives of differential equation solutions},
	Year = {2018}}

@article{rackauckas2019diffeqflux,
	Author = {Rackauckas, Chris and Innes, Mike and Ma, Yingbo and Bettencourt, Jesse and White, Lyndon and Dixit, Vaibhav},
	Journal = {arXiv preprint arXiv:1902.02376},
	Title = {Diffeqflux.jl-A julia library for neural differential equations},
	Year = {2019}}

@article{rackauckas2020universal,
	Author = {Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},
	Journal = {arXiv preprint arXiv:2001.04385},
	Title = {Universal Differential Equations for Scientific Machine Learning},
	Year = {2020}}

@article{sengupta2019going,
	Author = {Sengupta, Abhronil and Ye, Yuting and Wang, Robert and Liu, Chiao and Roy, Kaushik},
	Journal = {Frontiers in neuroscience},
	Pages = {95},
	Publisher = {Frontiers},
	Title = {Going deeper in spiking neural networks: Vgg and residual architectures},
	Volume = {13},
	Year = {2019}}

@article{esser:2016,
	Abstract = {Brain-inspired computing seeks to develop new technologies that solve real-world problems while remaining grounded in the physical requirements of energy, speed, and size. Meeting these challenges requires high-performing algorithms that are capable of running on efficient hardware. Here, we adapt deep convolutional neural networks, which are today{\textquoteright}s state-of-the-art approach for machine perception in many domains, to perform classification tasks on neuromorphic hardware, which is today{\textquoteright}s most efficient platform for running neural networks. Using our approach, we demonstrate near state-of-the-art accuracy on eight datasets, while running at between 1,200 and 2,600 frames/s and using between 25 and 275 mW.Deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. Independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. Here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (i) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (ii) perform inference while preserving the hardware{\textquoteright}s underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mW (effectively \&gt;6,000 frames/s per Watt), and (iii) can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer.},
	Author = {Esser, Steven K. and Merolla, Paul A. and Arthur, John V. and Cassidy, Andrew S. and Appuswamy, Rathinakumar and Andreopoulos, Alexander and Berg, David J. and McKinstry, Jeffrey L. and Melano, Timothy and Barch, Davis R. and di Nolfo, Carmelo and Datta, Pallab and Amir, Arnon and Taba, Brian and Flickner, Myron D. and Modha, Dharmendra S.},
	Doi = {10.1073/pnas.1604850113},
	Eprint = {https://www.pnas.org/content/113/41/11441.full.pdf},
	Issn = {0027-8424},
	Journal = {Proceedings of the National Academy of Sciences},
	Number = {41},
	Pages = {11441--11446},
	Publisher = {National Academy of Sciences},
	Title = {Convolutional networks for fast, energy-efficient neuromorphic computing},
	Url = {https://www.pnas.org/content/113/41/11441},
	Volume = {113},
	Year = {2016}}

@article{albada:2018,
	Author = {van Albada, Sacha Jennifer and Rowley, Andrew G and Senk, Johanna and Hopkins, Michael and Schmidt, Maximilian and Stokes, Alan Barry and Lester, David R and Diesmann, Markus and Furber, Steve B},
	Journal = {Frontiers in neuroscience},
	Pages = {291},
	Publisher = {Frontiers},
	Title = {Performance comparison of the digital neuromorphic hardware SpiNNaker and the neural network simulation software NEST for a full-scale cortical microcircuit model},
	Volume = {12},
	Year = {2018}}

@article{hughes:2000arrow,
	Author = {John Hughes},
	Doi = {https://doi.org/10.1016/S0167-6423(99)00023-4},
	Issn = {0167-6423},
	Journal = {Science of Computer Programming},
	Number = {1},
	Pages = {67 - 111},
	Title = {Generalising monads to arrows},
	Url = {http://www.sciencedirect.com/science/article/pii/S0167642399000234},
	Volume = {37},
	Year = {2000}}

@inproceedings{sculthorpe:2009,
	Address = {Edinburgh, Scotland},
	Author = {Neil Sculthorpe and Henrik Nilsson},
	Booktitle = {Proceedings of the Fourteenth {ACM} {SIGPLAN} International Conference on Functional Programming (ICFP'09)},
	Month = sep,
	Pages = {23--34},
	Publisher = {{ACM} Press},
	Title = {Safe Functional Reactive Programming through Dependent Types},
	Year = 2009}

@inproceedings{nilsson:2005,
	Address = {Tallinn, Estonia},
	Author = {Henrik Nilsson},
	Booktitle = {Proceedings of the Tenth {ACM} {SIGPLAN} International Conference on Functional Programming (ICFP'05)},
	Month = sep,
	Pages = {54--65},
	Publisher = {{ACM} Press},
	Title = {Dynamic Optimization for Functional Reactive Programming using Generalized Algebraic Data Types},
	Year = 2005}

@article{pei2019towards,
	Author = {Pei, Jing and Deng, Lei and Song, Sen and Zhao, Mingguo and Zhang, Youhui and Wu, Shuang and Wang, Guanrui and Zou, Zhe and Wu, Zhenzhi and He, Wei and others},
	Journal = {Nature},
	Number = {7767},
	Pages = {106--111},
	Publisher = {Nature Publishing Group},
	Title = {Towards artificial general intelligence with hybrid Tianjic chip architecture},
	Volume = {572},
	Year = {2019}}

@inproceedings{abadi:2016,
	Author = {Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
	Booktitle = {12th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 16)},
	Pages = {265--283},
	Title = {Tensorflow: A system for large-scale machine learning},
	Year = {2016}}

@article{joyal_street_verity:1996,
	Author = {Joyal, Andr{\'e} and Street, Ross and Verity, Dominic},
	Doi = {10.1017/S0305004100074338},
	Journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
	Number = {3},
	Pages = {447--468},
	Publisher = {Cambridge University Press},
	Title = {Traced monoidal categories},
	Volume = {119},
	Year = {1996}}

@article{joyal:1993braided,
	Author = {Joyal, Andr{\'e} and Street, Ross},
	Journal = {Advances in Mathematics},
	Number = {1},
	Pages = {20--78},
	Publisher = {New York: Academic Press, 1965-},
	Title = {Braided tensor categories},
	Volume = {102},
	Year = {1993}}

@book{mac:2013categories,
	Author = {Mac Lane, Saunders},
	Publisher = {Springer Science \& Business Media},
	Title = {Categories for the working mathematician},
	Volume = {5},
	Year = {2013}}

@book{etingof:2016tensor,
	Author = {Etingof, Pavel and Gelaki, Shlomo and Nikshych, Dmitri and Ostrik, Victor},
	Publisher = {American Mathematical Soc.},
	Title = {Tensor categories},
	Volume = {205},
	Year = {2016}}

@inproceedings{day:1970closed,
	Author = {Day, Brian},
	Booktitle = {Reports of the Midwest Category Seminar IV},
	Organization = {Springer},
	Pages = {1--38},
	Title = {On closed categories of functors},
	Year = {1970}}

@article{baez:2015control,
	Author = {Baez, John C and Erbele, Jason},
	Journal = {Theory and Applications of Categories},
	Number = {24},
	Pages = {836--881},
	Title = {Categories in control},
	Volume = {30},
	Year = {2015}}

@article{fong:2016algebra,
	Author = {Fong, Brendan},
	Journal = {arXiv preprint arXiv:1609.05382},
	Title = {The algebra of open and interconnected systems},
	Year = {2016}}

@article{wei:2017dlvm,
	Author = {Wei, Richard and Schwartz, Lane and Adve, Vikram},
	Journal = {arXiv preprint arXiv:1711.03016},
	Title = {DLVM: A modern compiler infrastructure for deep learning systems},
	Year = {2017}}

@article{vasilache:2018tensor,
	Author = {Vasilache, Nicolas and Zinenko, Oleksandr and Theodoridis, Theodoros and Goyal, Priya and DeVito, Zachary and Moses, William S and Verdoolaege, Sven and Adams, Andrew and Cohen, Albert},
	Journal = {arXiv preprint arXiv:1802.04730},
	Title = {Tensor comprehensions: Framework-agnostic high-performance machine learning abstractions},
	Year = {2018}}

@book{martin:1984,
	Author = {Martin-L{\"o}f, Per and Sambin, Giovanni},
	Publisher = {Bibliopolis Naples},
	Title = {Intuitionistic type theory},
	Volume = {9},
	Year = {1984}}

@book{lee2001:introduction,
	Author = {Lee, John M},
	Publisher = {Springer},
	Title = {Introduction to smooth manifolds},
	Year = {2001}}

@article{mcbride:2008applicative,
	Author = {McBride, Conor and Paterson, Ross},
	Journal = {Journal of functional programming},
	Number = {1},
	Pages = {1--13},
	Publisher = {Cambridge University Press},
	Title = {Applicative programming with effects},
	Volume = {18},
	Year = {2008}}

@book{kock:2006synthetic,
	Author = {Kock, A. and London Mathematical Society and Hitchin, N.J.},
	Isbn = {9780521687386},
	Lccn = {81006099},
	Publisher = {Cambridge University Press},
	Series = {Lecture note series / London mathematical society},
	Title = {Synthetic Differential Geometry},
	Year = {2006}}

@book{borceux1994:handbook,
	Author = {Borceux, F. and Rota, G.C. and Doran, B. and Flajolet, P. and Lam, T.Y. and Lutwak, E. and Ismail, M.},
	Isbn = {9780521441780},
	Lccn = {93003225},
	Publisher = {Cambridge University Press},
	Series = {Cambridge Textbooks in Linguis},
	Title = {Handbook of Categorical Algebra: Volume 1, Basic Category Theory},
	Year = {1994}}

@article{cuntz2010one,
  title={One rule to grow them all: a general theory of neuronal branching and its practical application},
  author={Cuntz, Hermann and Forstner, Friedrich and Borst, Alexander and H{\"a}usser, Michael},
  journal={PLoS Comput Biol},
  volume={6},
  number={8},
  pages={e1000877},
  year={2010},
  publisher={Public Library of Science}
}

@manual{cuntz:2010,
  title = "the TREES toolbox",
  author = {Cuntz, Hermann and Forstner, Friedrich and Borst, Alexander and H{\"a}usser, Michael},
  year = 2010
}

@misc{chen2020learning,
	Archiveprefix = {arXiv},
	Author = {Ricky T. Q. Chen and Brandon Amos and Maximilian Nickel},
	Eprint = {2011.03902},
	Primaryclass = {cs.LG},
	Title = {Learning Neural Event Functions for Ordinary Differential Equations},
	Year = {2020}}

@misc{chen2018neural,
	Archiveprefix = {arXiv},
	Author = {Ricky T. Q. Chen and Yulia Rubanova and Jesse Bettencourt and David Duvenaud},
	Eprint = {1806.07366},
	Primaryclass = {cs.LG},
	Title = {Neural Ordinary Differential Equations},
	Year = {2018}}

@article{kappel2015synaptic,
  title={Synaptic sampling: a bayesian approach to neural network plasticity and rewiring},
  author={Kappel, David and Habenschuss, Stefan and Legenstein, Robert and Maass, Wolfgang},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  pages={370--378},
  year={2015}
}

@incollection{NIPS2004_2674,
  title     = {Maximising Sensitivity in a Spiking Network},
  author    = {Anthony J. Bell and Lucas C. Parra},
  booktitle = {Advances in Neural Information Processing Systems 17},
  editor    = {L. K. Saul and Y. Weiss and L. Bottou},
  pages     = {121--128},
  year      = {2005},
  publisher = {MIT Press},
  url       = {http://papers.nips.cc/paper/2674-maximising-sensitivity-in-a-spiking-network.pdf}
}


@article{Booij2005,
  title    = {A gradient descent rule for spiking neurons emitting multiple spikes},
  journal  = {Information Processing Letters},
  volume   = {95},
  number   = {6},
  pages    = {552 - 558},
  year     = {2005},
  note     = {Applications of Spiking Neural Networks},
  issn     = {0020-0190},
  doi      = {https://doi.org/10.1016/j.ipl.2005.05.023},
  url      = {http://www.sciencedirect.com/science/article/pii/S0020019005001560},
  author   = {Olaf Booij and Hieu {tat Nguyen}},
  keywords = {Spiking neural networks, Temporal pattern recognition, Error-backpropagation, Parallel processing},
  abstract = {A supervised learning rule for Spiking Neural Networks (SNNs) is presented that can cope with neurons that spike multiple times. The rule is developed by extending the existing SpikeProp algorithm which could only be used for one spike per neuron. The problem caused by the discontinuity in the spike process is counteracted with a simple but effective rule, which makes the learning process more efficient. Our learning rule is successfully tested on a classification task of Poisson spike trains. We also applied the algorithm on a temporal version of the XOR problem and show that it is possible to learn this classical problem using only one spiking neuron making use of a hair-trigger situation.}
}


@article{Florian2012,
  author    = {Florian, RÄzvan V.},
  journal   = {PLOS ONE},
  publisher = {Public Library of Science},
  title     = {The Chronotron: A Neuron That Learns to Fire Temporally Precise Spike Patterns},
  year      = {2012},
  month     = {08},
  volume    = {7},
  url       = {https://doi.org/10.1371/journal.pone.0040233},
  pages     = {1-27},
  number    = {8},
  doi       = {10.1371/journal.pone.0040233}
}


@article{Yan2013,
  title   = {A supervised multi-spike learning algorithm based on gradient descent for spiking neural networks},
  author  = {Xu, Yan and Zeng, Xiaoqin and Han, Lixin and Yang, Jing},
  doi     = {10.1016/j.neunet.2013.02.003},
  volume  = {43},
  month   = {July},
  year    = {2013},
  journal = {Neural networks : the official journal of the International Neural Network Society},
  issn    = {0893-6080},
  pages   = {99â113},
  url     = {https://doi.org/10.1016/j.neunet.2013.02.003}
}

@misc{fong2016algebra,
      title={The Algebra of Open and Interconnected Systems}, 
      author={Brendan Fong},
      year={2016},
      eprint={1609.05382},
      archivePrefix={arXiv},
      primaryClass={math.CT}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  pages={5998--6008},
  year={2017}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{wenyu2014,
  author    = {Yang, Wenyu
and Yang, Dakun
and Fan, Yetian},
  editor    = {Zeng, Zhigang
and Li, Yangmin
and King, Irwin},
  title     = {A Proof of a Key Formula in the Error-Backpropagation Learning Algorithm for Multiple Spiking Neural Networks},
  booktitle = {Advances in Neural Networks -- ISNN 2014},
  year      = {2014},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {19--26},
  isbn      = {978-3-319-12436-0}
}


@book{gerstner2014neuronal,
	Author = {Gerstner, Wulfram and Kistler, Werner M and Naud, Richard and Paninski, Liam},
	Publisher = {Cambridge University Press},
	Title = {Neuronal dynamics: From single neurons to networks and models of cognition},
	Year = {2014}}

@article{wetterich:2018,
	Archiveprefix = {arXiv},
	Author = {Wetterich, C.},
	Doi = {10.1016/j.nuclphysb.2019.114776},
	Eprint = {1806.05960},
	Journal = {Nucl. Phys. B},
	Pages = {114776},
	Primaryclass = {quant-ph},
	Title = {{Quantum computing with classical bits}},
	Volume = {948},
	Year = {2019}}

@article{wetterich:2018information,
	Archiveprefix = {arXiv},
	Author = {Wetterich, C},
	Eprint = {1611.04820},
	Journal = {Nuclear Physics B},
	Pages = {35--96},
	Publisher = {Elsevier},
	Title = {Information transport in classical statistical systems},
	Volume = {927},
	Year = {2018}}

@incollection{tHooft1993planar,
  title={A planar diagram theory for strong interactions},
  author={'t Hooft, Gerard},
  booktitle={The Large N Expansion In Quantum Field Theory And Statistical Physics: From Spin Systems to 2-Dimensional Gravity},
  pages={80--92},
  year={1993},
  publisher={World Scientific}
}

@misc{wetterich2020probabilistic,
      title={The probabilistic world}, 
      author={C. Wetterich},
      year={2020},
      eprint={2011.02867},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@article{wetterich:2018quantum,
	Archiveprefix = {arXiv},
	Author = {Wetterich, C},
	Eprint = {1706.01772},
	Journal = {Annals of Physics},
	Pages = {1--70},
	Publisher = {Elsevier},
	Title = {Quantum formalism for classical statistics},
	Volume = {393},
	Year = {2018}}

@article{ginibre:1965,
	Author = {Ginibre,Jean},
	Doi = {10.1063/1.1704292},
	Eprint = {https://doi.org/10.1063/1.1704292},
	Journal = {Journal of Mathematical Physics},
	Number = {3},
	Pages = {440-449},
	Title = {Statistical Ensembles of Complex, Quaternion, and Real Matrices},
	Url = {https://doi.org/10.1063/1.1704292},
	Volume = {6},
	Year = {1965}}

@article{killoran:2018,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180403159K},
	Archiveprefix = {arXiv},
	Author = {{Killoran}, N. and {Izaac}, J. and {Quesada}, N. and {Bergholm}, V. and {Amy}, M. and {Weedbrook}, C.},
	Eprint = {1804.03159},
	Journal = {ArXiv e-prints},
	Keywords = {Quantum Physics, Physics - Computational Physics},
	Month = apr,
	Primaryclass = {quant-ph},
	Title = {{Strawberry Fields: A Software Platform for Photonic Quantum Computing}},
	Year = 2018}

@misc{google:2018,
	Author = {Google},
	Howpublished = {\url{https://github.com/quantumlib/Cirq}},
	Journal = {GitHub repository},
	Publisher = {GitHub},
	Title = {{Cirq}},
	Year = {2018}}

@article{mehta:2018,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180308823M},
	Archiveprefix = {arXiv},
	Author = {{Mehta}, P. and {Bukov}, M. and {Wang}, C.-H. and {Day}, A.~G.~R. and {Richardson}, C. and {Fisher}, C.~K. and {Schwab}, D.~J.},
	Eprint = {1803.08823},
	Journal = {ArXiv e-prints},
	Keywords = {Physics - Computational Physics, Condensed Matter - Statistical Mechanics, Computer Science - Learning, Statistics - Machine Learning},
	Month = mar,
	Primaryclass = {physics.comp-ph},
	Title = {{A high-bias, low-variance introduction to Machine Learning for physicists}},
	Year = 2018}

@article{lecun:2015,
	Author = {Yann LeCun and Yoshua Bengio and Geoffrey E. Hinton},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/nature/LeCunBH15},
	Doi = {10.1038/nature14539},
	Journal = {Nature},
	Number = {7553},
	Pages = {436--444},
	Timestamp = {Sat, 20 May 2017 01:00:00 +0200},
	Title = {Deep learning},
	Url = {https://doi.org/10.1038/nature14539},
	Volume = {521},
	Year = {2015}}

@techreport{duchi:2010,
	Author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	Institution = {EECS Department, University of California, Berkeley},
	Month = {Mar},
	Number = {UCB/EECS-2010-24},
	Title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
	Url = {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-24.html},
	Year = {2010}}

@article{petrovici:2016,
	Author = {Petrovici, Mihai A. and Bill, Johannes and Bytschok, Ilja and Schemmel, Johannes and Meier, Karlheinz},
	Doi = {10.1103/PhysRevE.94.042312},
	Issue = {4},
	Journal = {Phys. Rev. E},
	Month = {Oct},
	Numpages = {14},
	Pages = {042312},
	Publisher = {American Physical Society},
	Title = {Stochastic inference with spiking neurons in the high-conductance state},
	Url = {https://link.aps.org/doi/10.1103/PhysRevE.94.042312},
	Volume = {94},
	Year = {2016}}

@article{friedmann:2017,
	Author = {Friedmann, Simon and Schemmel, Johannes and Gr{\"u}bl, Andreas and Hartel, Andreas and Hock, Matthias and Meier, Karlheinz},
	Journal = {IEEE transactions on biomedical circuits and systems},
	Number = {1},
	Pages = {128--142},
	Publisher = {IEEE},
	Title = {Demonstrating hybrid learning in a flexible neuromorphic hardware system},
	Volume = {11},
	Year = {2017}}

@article{dold:2018,
	Author = {Dold, Dominik and Bytschok, Ilja and Kungl, Akos F and Baumbach, Andreas and Breitwieser, Oliver and Senn, Walter and Schemmel, Johannes and Meier, Karlheinz and Petrovici, Mihai A},
	Journal = {arXiv preprint arXiv:1809.08045},
	Title = {Stochasticity from function-why the Bayesian brain may need no noise},
	Year = {2018}}

@article{zeiler:2012,
	Archiveprefix = {arXiv},
	Author = {Matthew D. Zeiler},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1212-5701},
	Eprint = {1212.5701},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:45:57 +0200},
	Title = {{ADADELTA:} An Adaptive Learning Rate Method},
	Url = {http://arxiv.org/abs/1212.5701},
	Volume = {abs/1212.5701},
	Year = {2012}}

@misc{chollet:2015,
	Author = {Chollet, Fran\c{c}ois and others},
	Howpublished = {\url{https://keras.io}},
	Title = {Keras},
	Year = {2015}}

@misc{tensorflow:2015,
	Author = {Mart\'{\i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and Andy~Davis and Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~Kudlur and Josh~Levenberg and Dandelion~Man\'{e} and Rajat~Monga and Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and Fernanda~Vi\'{e}gas and Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
	Note = {Software available from tensorflow.org},
	Title = {{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	Url = {https://www.tensorflow.org/},
	Year = {2015}}

@article{carleo:2016,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017Sci...355..602C},
	Archiveprefix = {arXiv},
	Author = {{Carleo}, G. and {Troyer}, M.},
	Doi = {10.1126/science.aag2302},
	Eprint = {1606.02318},
	Journal = {Science},
	Month = feb,
	Pages = {602-606},
	Primaryclass = {cond-mat.dis-nn},
	Title = {{Solving the quantum many-body problem with artificial neural networks}},
	Volume = 355,
	Year = 2017}

@article{buesing:2011,
	Abstract = {Author Summary It is well-known that neurons communicate with short electric pulses, called action potentials or spikes. But how can spiking networks implement complex computations? Attempts to relate spiking network activity to results of deterministic computation steps, like the output bits of a processor in a digital computer, are conflicting with findings from cognitive science and neuroscience, the latter indicating the neural spike output in identical experiments changes from trial to trial, i.e., neurons are {\^a}ÂÂunreliable{\^a}ÂÂ. Therefore, it has been recently proposed that neural activity should rather be regarded as samples from an underlying probability distribution over many variables which, e.g., represent a model of the external world incorporating prior knowledge, memories as well as sensory input. This hypothesis assumes that networks of stochastically spiking neurons are able to emulate powerful algorithms for reasoning in the face of uncertainty, i.e., to carry out probabilistic inference. In this work we propose a detailed neural network model that indeed fulfills these computational requirements and we relate the spiking dynamics of the network to concrete probabilistic computations. Our model suggests that neural systems are suitable to carry out probabilistic inference by using stochastic, rather than deterministic, computing elements.},
	Author = {Buesing, Lars AND Bill, Johannes AND Nessler, Bernhard AND Maass, Wolfgang},
	Doi = {10.1371/journal.pcbi.1002211},
	Journal = {PLOS Computational Biology},
	Month = {11},
	Number = {11},
	Pages = {1-22},
	Publisher = {Public Library of Science},
	Title = {Neural Dynamics as Sampling: A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons},
	Url = {https://doi.org/10.1371/journal.pcbi.1002211},
	Volume = {7},
	Year = {2011}}

@article{swaddle:2017,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017PhLA..381.3391S},
	Archiveprefix = {arXiv},
	Author = {{Swaddle}, M. and {Noakes}, L. and {Smallbone}, H. and {Salter}, L. and {Wang}, J.},
	Doi = {10.1016/j.physleta.2017.08.043},
	Eprint = {1703.10743},
	Journal = {Physics Letters A},
	Keywords = {Quantum computation, Quantum compiling, Neural networks, subRiemannian geometry},
	Month = oct,
	Pages = {3391-3395},
	Primaryclass = {quant-ph},
	Title = {{Generating three-qubit quantum circuits with neural networks}},
	Volume = 381,
	Year = 2017}

@book{pontryagin:1962,
	Author = {Pontryagin, Lev Semenovich},
	Publisher = {Routledge},
	Title = {Mathematical theory of optimal processes},
	Year = {1962}}

@inproceedings{bellec:2018,
	Author = {Bellec, Guillaume and Salaj, Darjan and Subramoney, Anand and Legenstein, Robert and Maass, Wolfgang},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {787--797},
	Title = {Long short-term memory and learning-to-learn in networks of spiking neurons},
	Year = {2018}}

@software{jax:2018,
	Author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and Skye Wanderman-Milne},
	Title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
	Url = {http://github.com/google/jax},
	Version = {0.1.55},
	Year = {2018},
	Bdsk-Url-1 = {http://github.com/google/jax}}

@article{torlai:2018,
	Abstract = {The experimental realization of increasingly complex synthetic quantum systems calls for the development of general theoretical methods to validate and fully exploit quantum resources. Quantum state tomography (QST) aims to reconstruct the full quantum state from simple measurements, and therefore provides a key tool to obtain reliable analytics1--3. However, exact brute-force approaches to QST place a high demand on computational resources, making them unfeasible for anything except small systems4,5. Here we show how machine learning techniques can be used to perform QST of highly entangled states with more than a hundred qubits, to a high degree of accuracy. We demonstrate that machine learning allows one to reconstruct traditionally challenging many-body quantities---such as the entanglement entropy---from simple, experimentally accessible measurements. This approach can benefit existing and future generations of devices ranging from quantum computers to ultracold-atom quantum simulators6--8.},
	Author = {Torlai, Giacomo and Mazzola, Guglielmo and Carrasquilla, Juan and Troyer, Matthias and Melko, Roger and Carleo, Giuseppe},
	Da = {2018/05/01},
	Date-Added = {2020-04-27 16:35:22 +0200},
	Date-Modified = {2020-04-27 16:35:43 +0200},
	Doi = {10.1038/s41567-018-0048-5},
	Id = {Torlai2018},
	Isbn = {1745-2481},
	Journal = {Nature Physics},
	Number = {5},
	Pages = {447--450},
	Title = {Neural-network quantum state tomography},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41567-018-0048-5},
	Volume = {14},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41567-018-0048-5}}

@article{schneidman:2006,
	Author = {Schneidman, Elad and Berry, Michael J and Segev, Ronen and Bialek, William},
	Journal = {Nature},
	Number = {7087},
	Pages = {1007--1012},
	Publisher = {Nature Publishing Group},
	Title = {Weak pairwise correlations imply strongly correlated network states in a neural population},
	Volume = {440},
	Year = {2006}}

@article{hopfield:1982,
	Author = {Hopfield, John J},
	Journal = {Proceedings of the national academy of sciences},
	Number = {8},
	Pages = {2554--2558},
	Publisher = {National Acad Sciences},
	Title = {Neural networks and physical systems with emergent collective computational abilities},
	Volume = {79},
	Year = {1982}}

@article{pinna:2018,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Archiveprefix = {arXiv},
	Author = {{Pinna}, D. and {Abreu Araujo}, F. and {Kim}, J. -V. and {Cros}, V. and {Querlioz}, D. and {Bessiere}, P. and {Droulez}, J. and {Grollier}, J.},
	Eid = {064018},
	Eprint = {1701.07750},
	Journal = {Physical Review Applied},
	Keywords = {Condensed Matter - Mesoscale and Nanoscale Physics, Condensed Matter - Disordered Systems and Neural Networks, Physics - Computational Physics},
	Month = Jun,
	Pages = {064018},
	Primaryclass = {cond-mat.mes-hall},
	Title = {{Skyrmion Gas Manipulation for Probabilistic Computing}},
	Volume = {9},
	Year = 2018}

@article{faix:2018,
	Author = {M. Faix and R. Laurent and P. Bessiere and E. Mazer and J. Droulez},
	Doi = {10.1109/TETC.2016.2609926},
	Issn = {2168-6750},
	Journal = {IEEE Transactions on Emerging Topics in Computing},
	Keywords = {Bayes methods;Computer architecture;Probabilistic logic;Hardware;Logic gates;Correlation;Programming;Stochastic computing;Bayesian Programming},
	Pages = {1-1},
	Title = {Design of Stochastic Machines Dedicated to Approximate Bayesian inferences},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/TETC.2016.2609926}}

@article{hodgkin:1952,
	Author = {Hodgkin, A. L. and Huxley, A. F.},
	Doi = {10.1113/jphysiol.1952.sp004764},
	Journal = {The Journal of Physiology},
	Number = {4},
	Pages = {500-544},
	Title = {A quantitative description of membrane current and its application to conduction and excitation in nerve},
	Volume = {117},
	Year = {1952},
	Bdsk-Url-1 = {https://doi.org/10.1113/jphysiol.1952.sp004764}}

@inproceedings{qiao:2016,
	Author = {Qiao, Ning and Indiveri, Giacomo},
	Booktitle = {Biomedical Circuits and Systems Conference (BioCAS), 2016 IEEE},
	Organization = {IEEE},
	Pages = {552--555},
	Title = {Scaling mixed-signal neuromorphic processors to 28 nm FD-SOI technologies},
	Year = {2016}}

@article{neftci2013stochastic,
	Archiveprefix = {arXiv},
	Author = {Emre Neftci and Srinjoy Das and Bruno U. Pedroni and Kenneth Kreutz{-}Delgado and Gert Cauwenberghs},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/NeftciDPKC13},
	Eprint = {1311.0966},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:47:07 +0200},
	Title = {Event-Driven Contrastive Divergence for Spiking Neuromorphic Systems},
	Url = {http://arxiv.org/abs/1311.0966},
	Volume = {abs/1311.0966},
	Year = {2013},
	Bdsk-Url-1 = {http://arxiv.org/abs/1311.0966}}

@article{friedman:2016a,
	Author = {J. S. Friedman and L. E. Calvet and P. Bessi{\`e}re and J. Droulez and D. Querlioz},
	Doi = {10.1109/TCSI.2016.2546064},
	Issn = {1549-8328},
	Journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
	Keywords = {decision making;filters;network synthesis;stochastic processes;Bayesian inference;Muller C-elements;stochastic signals;C-element trees;probability;multiple independent sources;naive Bayesian spam filter circuit;signal autocorrelation;stochastic inference structure;area-energy-delay product;embedded decision circuits;Bayes methods;Switches;Correlation;Hardware;Probabilistic logic;Robots;Nanoscale devices;Fault-tolerant circuit design;Muller C-element;nanotechnology;stochastic computing;variation-prone devices},
	Month = {June},
	Number = {6},
	Pages = {895-904},
	Title = {Bayesian Inference With Muller C-Elements},
	Volume = {63},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1109/TCSI.2016.2546064}}

@article{canals:2016,
	Author = {V. Canals and A. Morro and A. Oliver and M. L. Alomar and J. L. Rossell{\'o}},
	Doi = {10.1109/TNNLS.2015.2413754},
	Issn = {2162-237X},
	Journal = {IEEE Transactions on Neural Networks and Learning Systems},
	Keywords = {encoding;neural nets;parallel processing;pattern recognition;probabilistic logic;regression analysis;stochastic processes;stochastic computing methodology;neural network implementation;probabilistic laws;unipolar encoding;bipolar encoding;bipolar-encoded pulsed signals;total noise-immunity capability;regression;pattern recognition task;highly reliable systems;parallel computing;Logic gates;Probabilistic logic;Artificial neural networks;Switches;Encoding;Hardware;Computational intelligence;neural networks (NNs);pattern recognition;probabilistic logic;stochastic systems.;Computational intelligence;neural networks (NNs);pattern recognition;probabilistic logic;stochastic systems},
	Month = {March},
	Number = {3},
	Pages = {551-564},
	Title = {A New Stochastic Computing Methodology for Efficient Neural Network Implementation},
	Volume = {27},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1109/TNNLS.2015.2413754}}

@article{neumann:56,
	Author = {Von Neumann, John},
	Journal = {Automata studies},
	Pages = {43--98},
	Title = {Probabilistic logics and the synthesis of reliable organisms from unreliable components},
	Volume = {34},
	Year = {1956}}

@article{buesing2011neural,
	Author = {Buesing, Lars and Bill, Johannes and Nessler, Bernhard and Maass, Wolfgang},
	Journal = {PLoS computational biology},
	Number = {11},
	Pages = {e1002211},
	Publisher = {Public Library of Science},
	Title = {Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons},
	Volume = {7},
	Year = {2011}}

@book{dayan:2005,
	Author = {Dayan, Peter and Abbott, Laurence F},
	Publisher = {Computational Neuroscience Series},
	Title = {Theoretical neuroscience: computational and mathematical modeling of neural systems},
	Year = {2001}}

@article{london:2005,
	Author = {London, Michael and H{\"a}usser, Michael},
	Journal = {Annu. Rev. Neurosci.},
	Pages = {503--532},
	Publisher = {Annual Reviews},
	Title = {Dendritic computation},
	Volume = {28},
	Year = {2005}}

@article{torrejon2017neuromorphic,
	Author = {Torrejon, Jacob and Riou, Mathieu and Araujo, Flavio Abreu and Tsunegi, Sumito and Khalsa, Guru and Querlioz, Damien and Bortolotti, Paolo and Cros, Vincent and Yakushiji, Kay and Fukushima, Akio and others},
	Journal = {Nature},
	Number = {7664},
	Pages = {428},
	Publisher = {Nature Publishing Group},
	Title = {Neuromorphic computing with nanoscale spintronic oscillators},
	Volume = {547},
	Year = {2017}}

@article{Gerstner:1996,
	Abstract = {An unresolved paradox exists in auditory and  electrosensory neural systems {Carr93,Heiligenberg91}: they  encode behaviourally relevant signals in the range of a few  microseconds with neurons that are at least one order of  magnitude slower. We take the barn owl's auditory system as  an example and present a modeling study based on computer  simulations of a neuron in the laminar nucleus. Three  observations resolve the paradox. First, spiking of an  integrate-and-fire neuron driven by excitatory postsynaptic  potentials (EPSPs) with a width at half maximum of 250  microseconds has an accuracy of 25 microseconds if the  presynaptic signals arrive coherently. Second, the  necessary degree of coherence in the signal arrival times  can be attained during ontogenetic development by virtue of  an unsupervised Hebbian learning rule. Learning selects  connections with matching delays from a broad distribution  of axons with random delays. Third, the learning rule also  selects the correct delays from two independent groups of  inputs, for example, from the left and right ear.},
	Author = {Gerstner, W. and Kempter, R. and van Hemmen, J. Leo and Wagner, H.},
	Journal = {Nature},
	Note = {article},
	Number = {6595},
	Pages = {76-78},
	Title = {A neuronal learning rule for sub-millisecond temporal coding},
	Volume = {383},
	Year = {1996}}

@inproceedings{glorot:2011,
	Author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
	Booktitle = {Proceedings of the fourteenth international conference on artificial intelligence and statistics},
	Pages = {315--323},
	Title = {Deep sparse rectifier neural networks},
	Year = {2011}}

@article{mcculloch:1943,
	Author = {McCulloch, Warren S and Pitts, Walter},
	Journal = {The bulletin of mathematical biophysics},
	Number = {4},
	Pages = {115--133},
	Publisher = {Springer},
	Title = {A logical calculus of the ideas immanent in nervous activity},
	Volume = {5},
	Year = {1943}}

@inproceedings{jaderberg2017decoupled,
	Author = {Jaderberg, Max and Czarnecki, Wojciech Marian and Osindero, Simon and Vinyals, Oriol and Graves, Alex and Silver, David and Kavukcuoglu, Koray},
	Booktitle = {International Conference on Machine Learning},
	Organization = {PMLR},
	Pages = {1627--1635},
	Title = {Decoupled neural interfaces using synthetic gradients},
	Year = {2017}}

@article{moore1956gedanken,
	Author = {Moore, Edward F and others},
	Journal = {Automata studies},
	Pages = {129--153},
	Title = {Gedanken-experiments on sequential machines},
	Volume = {34},
	Year = {1956}}

@article{levine:2019,
	Author = {Levine, Yoav and Sharir, Or and Cohen, Nadav and Shashua, Amnon},
	Journal = {Physical review letters},
	Number = {6},
	Pages = {065301},
	Publisher = {APS},
	Title = {Quantum entanglement in deep learning architectures},
	Volume = {122},
	Year = {2019}}

@article{ohiorhenuan:2010,
	Author = {Ohiorhenuan, Ifije E and Mechler, Ferenc and Purpura, Keith P and Schmid, Anita M and Hu, Qin and Victor, Jonathan D},
	Journal = {Nature},
	Number = {7306},
	Pages = {617--621},
	Publisher = {Nature Publishing Group},
	Title = {Sparse coding and high-order correlations in fine-scale cortical networks},
	Volume = {466},
	Year = {2010}}

@article{james:2001,
	Author = {James, Daniel F. V. and Kwiat, Paul G. and Munro, William J. and White, Andrew G.},
	Doi = {10.1103/PhysRevA.64.052312},
	Issue = {5},
	Journal = {Phys. Rev. A},
	Month = {Oct},
	Numpages = {15},
	Pages = {052312},
	Publisher = {American Physical Society},
	Title = {Measurement of qubits},
	Url = {https://link.aps.org/doi/10.1103/PhysRevA.64.052312},
	Volume = {64},
	Year = {2001},
	Bdsk-Url-1 = {https://link.aps.org/doi/10.1103/PhysRevA.64.052312},
	Bdsk-Url-2 = {https://doi.org/10.1103/PhysRevA.64.052312}}

@book{paris:2004,
	Author = {Paris, Matteo and Rehacek, Jaroslav},
	Publisher = {Springer Science \& Business Media},
	Title = {Quantum state estimation},
	Volume = {649},
	Year = {2004}}

@phdthesis{kiesel:2007,
	Author = {Kiesel, Nikolai},
	School = {lmu},
	Title = {Experiments on multiphoton entanglement},
	Year = {2007}}

@article{silver:2017,
	Author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
	Journal = {arXiv preprint arXiv:1712.01815},
	Title = {Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
	Year = {2017}}

@article{silver:2016,
	Author = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
	Journal = {nature},
	Number = {7587},
	Pages = {484},
	Publisher = {Nature Publishing Group},
	Title = {Mastering the game of Go with deep neural networks and tree search},
	Volume = {529},
	Year = {2016}}

@incollection{selinger:2010,
	Author = {Selinger, Peter},
	Booktitle = {New structures for physics},
	Pages = {289--355},
	Publisher = {Springer},
	Title = {A survey of graphical languages for monoidal categories},
	Year = {2010}}

@article{church:1940,
	Author = {Church, Alonzo},
	Journal = {The journal of symbolic logic},
	Number = {2},
	Pages = {56--68},
	Publisher = {Cambridge University Press},
	Title = {A formulation of the simple theory of types},
	Volume = {5},
	Year = {1940}}

@article{curry:1958,
	Author = {Curry, Haskell B},
	Isbn = {9780720422085},
	Title = {Combinatory logic},
	Year = {1958}}

@article{elliott:2018,
	Author = {Elliott, Conal},
	Journal = {Proceedings of the ACM on Programming Languages},
	Number = {ICFP},
	Pages = {70},
	Publisher = {ACM},
	Title = {The simple essence of automatic differentiation},
	Volume = {2},
	Year = {2018}}

@phdthesis{girard:1972,
	Author = {Girard, Jean-Yves},
	School = {PhD thesis, Universit{\'e} Paris VII},
	Title = {Interpr{\'e}tation fonctionelle et {\'e}limination des coupures de l'arithm{\'e}tique d'ordre sup{\'e}rieur},
	Year = {1972}}

@article{moggi:1991,
	Abstract = {The Î»-calculus is considered a useful mathematical tool in the study of programming languages, since programs can be identified with Î»-terms. However, if one goes further and uses Î²Î·-conversion to prove equivalence of programs, then a gross simplification is introduced (programs are identified with total functions from values to values) that may jeopardise the applicability of theoretical results. In this paper we introduce calculi, based on a categorical semantics for computations, that provide a correct basis for proving equivalence of programs for a wide range of notions of computation.},
	Author = {Eugenio Moggi},
	Doi = {https://doi.org/10.1016/0890-5401(91)90052-4},
	Issn = {0890-5401},
	Journal = {Information and Computation},
	Note = {Selections from 1989 IEEE Symposium on Logic in Computer Science},
	Number = {1},
	Pages = {55 - 92},
	Title = {Notions of computation and monads},
	Url = {http://www.sciencedirect.com/science/article/pii/0890540191900524},
	Volume = {93},
	Year = {1991},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0890540191900524},
	Bdsk-Url-2 = {https://doi.org/10.1016/0890-5401(91)90052-4}}

@book{tu:2010,
	Author = {Tu, L.W.},
	Isbn = {9781441973993},
	Lccn = {2010936466},
	Publisher = {Springer New York},
	Series = {Universitext},
	Title = {An Introduction to Manifolds},
	Url = {https://books.google.de/books?id=br1KngEACAAJ},
	Year = {2010},
	Bdsk-Url-1 = {https://books.google.de/books?id=br1KngEACAAJ}}

@book{sussman:2013,
	Author = {Sussman, Gerald Jay and Wisdom, Jack},
	Publisher = {MIT Press},
	Title = {Functional differential geometry},
	Year = {2013}}

@inproceedings{selsam:2017,
	Author = {Daniel Selsam and Percy Liang and David L. Dill},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/conf/icml/SelsamLD17},
	Booktitle = {Proceedings of the 34th International Conference on Machine Learning, {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
	Crossref = {DBLP:conf/icml/2017},
	Pages = {3047--3056},
	Timestamp = {Wed, 16 Aug 2017 11:08:55 +0200},
	Title = {Developing Bug-Free Machine Learning Systems With Formal Mathematics},
	Url = {http://proceedings.mlr.press/v70/selsam17a.html},
	Year = {2017},
	Bdsk-Url-1 = {http://proceedings.mlr.press/v70/selsam17a.html}}

@proceedings{DBLP:conf/icml/2017,
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/conf/icml/2017},
	Editor = {Doina Precup and Yee Whye Teh},
	Publisher = {{PMLR}},
	Series = {Proceedings of Machine Learning Research},
	Timestamp = {Wed, 16 Aug 2017 11:08:55 +0200},
	Title = {Proceedings of the 34th International Conference on Machine Learning, {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
	Url = {http://jmlr.org/proceedings/papers/v70/},
	Volume = {70},
	Year = {2017},
	Bdsk-Url-1 = {http://jmlr.org/proceedings/papers/v70/}}

@inproceedings{moura:2015,
	Author = {de Moura, Leonardo and Kong, Soonho and Avigad, Jeremy and Van Doorn, Floris and von Raumer, Jakob},
	Booktitle = {International Conference on Automated Deduction},
	Organization = {Springer},
	Pages = {378--388},
	Title = {The Lean theorem prover (system description)},
	Year = {2015}}

@article{friedman:2016b,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {https://ui.adsabs.harvard.edu/\#abs/2016arXiv160405080F},
	Archiveprefix = {arXiv},
	Author = {{Friedmann}, Simon and {Schemmel}, Johannes and {Gruebl}, Andreas and {Hartel}, Andreas and {Hock}, Matthias and {Meier}, Karlheinz},
	Eid = {arXiv:1604.05080},
	Eprint = {1604.05080},
	Journal = {arXiv e-prints},
	Keywords = {Quantitative Biology - Neurons and Cognition, Condensed Matter - Disordered Systems and Neural Networks, Computer Science - Neural and Evolutionary Computing},
	Month = Apr,
	Pages = {arXiv:1604.05080},
	Primaryclass = {q-bio.NC},
	Title = {{Demonstrating Hybrid Learning in a Flexible Neuromorphic Hardware System}},
	Year = 2016}

@article{dean:2018,
	Author = {J. {Dean} and D. {Patterson} and C. {Young}},
	Doi = {10.1109/MM.2018.112130030},
	Issn = {0272-1732},
	Journal = {IEEE Micro},
	Keywords = {computer architecture;general purpose computers;learning (artificial intelligence);linear algebra;power aware computing;Googles Tensor Processing Unit;ML computing;computing systems;Dennard scaling;general-purpose program performance;machine learning;low-precision linear algebra;domain-specific architectures;Object recognition;IP networks;Frequency modulation;Computer architecture;Machine learning;Training data;machine learning;hardware;microarchitecture},
	Month = {Mar},
	Number = {2},
	Pages = {21-29},
	Title = {A New Golden Age in Computer Architecture: Empowering the Machine-Learning Revolution},
	Volume = {38},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/MM.2018.112130030}}

@article{hassabis:2017,
	Author = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
	Journal = {Neuron},
	Number = {2},
	Pages = {245--258},
	Publisher = {Elsevier},
	Title = {Neuroscience-inspired artificial intelligence},
	Volume = {95},
	Year = {2017}}

@article{mead:1990,
	Author = {Mead, Carver},
	Journal = {Proceedings of the IEEE},
	Number = {10},
	Pages = {1629--1636},
	Publisher = {IEEE},
	Title = {Neuromorphic electronic systems},
	Volume = {78},
	Year = {1990}}

@article{elliot2018adextended,
	Author = {Conal Elliott},
	Journal = {CoRR},
	Mon = mar,
	Title = {The simple essence of automatic differentiation (Extended version)},
	Url = {https://arxiv.org/abs/1804.00746},
	Volume = {abs/1804.00746},
	Year = {2018},
	Bdsk-Url-1 = {https://arxiv.org/abs/1804.00746}}

@inproceedings{hennessy:2018,
	Author = {Hennessy, John and Patterson, David},
	Booktitle = {2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)},
	Doi = {10.1109/ISCA.2018.00011},
	Issn = {2575-713X},
	Keywords = {Computer architecture;Security;Technological innovation;Timing;Instruction sets;Chip scale packaging},
	Month = {June},
	Pages = {27-29},
	Title = {A new golden age for computer architecture: Domain-specific hardware/software co-design, enhanced security, open instruction sets, and agile chip development},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/ISCA.2018.00011}}

@article{merolla:2014,
	Author = {Merolla, Paul A and Arthur, John V and Alvarez-Icaza, Rodrigo and Cassidy, Andrew S and Sawada, Jun and Akopyan, Filipp and Jackson, Bryan L and Imam, Nabil and Guo, Chen and Nakamura, Yutaka and others},
	Journal = {Science},
	Number = {6197},
	Pages = {668--673},
	Publisher = {American Association for the Advancement of Science},
	Title = {A million spiking-neuron integrated circuit with a scalable communication network and interface},
	Volume = {345},
	Year = {2014}}

@article{qiao:2015,
	Author = {Qiao, Ning and Mostafa, Hesham and Corradi, Federico and Osswald, Marc and Stefanini, Fabio and Sumislawska, Dora and Indiveri, Giacomo},
	Journal = {Frontiers in neuroscience},
	Pages = {141},
	Publisher = {Frontiers},
	Title = {A reconfigurable on-line learning spiking neuromorphic processor comprising 256 neurons and 128K synapses},
	Volume = {9},
	Year = {2015}}

@article{davies:2018,
	Author = {Davies, Mike and Srinivasa, Narayan and Lin, Tsung-Han and Chinya, Gautham and Cao, Yongqiang and Choday, Sri Harsha and Dimou, Georgios and Joshi, Prasad and Imam, Nabil and Jain, Shweta and others},
	Journal = {IEEE Micro},
	Number = {1},
	Pages = {82--99},
	Publisher = {IEEE},
	Title = {Loihi: A neuromorphic manycore processor with on-chip learning},
	Volume = {38},
	Year = {2018}}

@article{furber2016large,
	Author = {Furber, Steve},
	Journal = {Journal of neural engineering},
	Number = {5},
	Pages = {051001},
	Publisher = {IOP Publishing},
	Title = {Large-scale neuromorphic computing systems},
	Volume = {13},
	Year = {2016}}

@article{brockman2016openai,
	Author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	Journal = {arXiv preprint arXiv:1606.01540},
	Title = {Openai gym},
	Year = {2016}}

@article{kungl2019accelerated,
	Author = {Kungl, Akos F and Schmitt, Sebastian and Kl{\"a}hn, Johann and M{\"u}ller, Paul and Baumbach, Andreas and Dold, Dominik and Kugele, Alexander and M{\"u}ller, Eric and Koke, Christoph and Kleider, Mitja and others},
	Journal = {Frontiers in neuroscience},
	Pages = {1201},
	Publisher = {Frontiers},
	Title = {Accelerated physical emulation of Bayesian inference in spiking neural networks},
	Volume = {13},
	Year = {2019}}

@inproceedings{billaudelle2019versatile,
	Author = {Billaudelle, Sebastian and Stradmann, Yannik and Schreiber, Korbinian and Cramer, Benjamin and Baumbach, Andreas and Dold, Dominik and G{\"o}ltz, Julian and Kungl, Akos F and Wunderlich, Timo C and Hartel, Andreas and others},
	Booktitle = {2020 IEEE International Symposium on Circuits and Systems (ISCAS)},
	Organization = {IEEE},
	Pages = {1--5},
	Title = {Versatile emulation of spiking neural networks on an accelerated neuromorphic substrate},
	Year = {2020}}

@article{barto1983neuronlike,
	Author = {Barto, Andrew G and Sutton, Richard S and Anderson, Charles W},
	Journal = {IEEE transactions on systems, man, and cybernetics},
	Number = {5},
	Pages = {834--846},
	Publisher = {IEEE},
	Title = {Neuronlike adaptive elements that can solve difficult learning control problems},
	Year = {1983}}

@phdthesis{FriedmannPhd:2013,
	Author = {Friedmann, Simon},
	School = {Heidelberg University},
	Title = {A new approach to learning in neuromorphic hardware},
	Year = {2013}}

@article{goltz2019fast,
	Author = {G{\"o}ltz, Julian and Baumbach, Andreas and Billaudelle, Sebastian and Breitwieser, Oliver and Dold, Dominik and Kriener, Laura and Kungl, Akos Ferenc and Senn, Walter and Schemmel, Johannes and Meier, Karlheinz and others},
	Journal = {arXiv preprint arXiv:1912.11443},
	Title = {Fast and deep neuromorphic learning with time-to-first-spike coding},
	Year = {2019}}

@article{elliott:2017,
	Acmid = {3110271},
	Address = {New York, NY, USA},
	Articleno = {27},
	Author = {Elliott, Conal},
	Doi = {10.1145/3110271},
	Issn = {2475-1421},
	Issue_Date = {September 2017},
	Journal = {Proc. ACM Program. Lang.},
	Keywords = {category theory, compile-time optimization, domain-specific languages},
	Month = aug,
	Number = {ICFP},
	Numpages = {27},
	Pages = {27:1--27:27},
	Publisher = {ACM},
	Title = {Compiling to Categories},
	Url = {http://doi.acm.org/10.1145/3110271},
	Volume = {1},
	Year = {2017},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/3110271},
	Bdsk-Url-2 = {https://doi.org/10.1145/3110271}}

@inproceedings{paszke:2017,
	Author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	Booktitle = {NIPS-W},
	Title = {Automatic differentiation in PyTorch},
	Year = {2017}}

@inproceedings{zelus:2013,
  visiblekey = {HSCC13},
  author = {Timothy Bourke and Marc Pouzet},
  title = {ZÃÂ©lus: A Synchronous Language with {ODEs}},
  booktitle = {16th International Conference on Hybrid Systems:
		 Computation and Control (HSCC'13)},
  pages = {113--118},
  month = mar,
  year = 2013,
  address = {Philadelphia, USA},
  url = {http://www.di.ens.fr/~pouzet/bib/hscc13.pdf},
  abstract = {
	ZÃÂ©lus is a new programming language for modeling systems that
	mix discrete logical time and continuous time behaviors. From a
	user's perspective, its main originality is to extend an existing
	Lustre-like synchronous language with Ordinary Differential
	Equations (ODEs). The extension is conservative: any synchronous
	program expressed as data-flow equations and hierarchical automata
	can be composed arbitrarily with ODEs in \emph{the same source code}.
	A dedicated type system and causality analysis ensure that all
	discrete changes are aligned with zero-crossing events so that no
	side effects or discontinuities occur during integration. Programs
	are statically scheduled and translated into sequential code that,
	by construction, runs in bounded time and space. Compilation is
	effected by source-to-source translation into a small synchronous
	subset which is processed by a standard synchronous compiler
	architecture. The resultant code is paired with an off-the-shelf
	numeric solver.
	We show that it is possible to build a modeler for explicit hybrid
	systems \emph{Ã  la Simulink/Stateflow} on top of an existing
	synchronous language, using it both as a semantic basis and as a
	target for code generation.
  }
}

@article{PhysRevLett.124.020503,
  title = {Deep Autoregressive Models for the Efficient Variational Simulation of Many-Body Quantum Systems},
  author = {Sharir, Or and Levine, Yoav and Wies, Noam and Carleo, Giuseppe and Shashua, Amnon},
  journal = {Phys. Rev. Lett.},
  volume = {124},
  issue = {2},
  pages = {020503},
  numpages = {6},
  year = {2020},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.124.020503},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.124.020503}
}

@incollection{zelus:2019,
  author = {Albert Benveniste and
  Benoit Caillaud and Hilding Elmquist and Khalil Ghorbal and
  Martin Otter and Marc Pouzet},
  title = {Multi-Mode DAE Models - Challenges, Theory and
                  Implementation. },
  booktitle = {Computing and Software Science: state of the Art and
                  Perspectives},
  editor = {Steffen B., Woeginger G.},
  publisher = {Springer},
  year = 2019,
  volume = 10000,
  series = {Lecture Notes in Computer Science},
  abstract = {Our objective is to model and simulate Cyber-Physical
                  Systems (CPS) such as robots, vehicles, and power
                  plants. The structure of CPS models may change
                  during simulation due to the desired operation, due
                  to failure situations or due to changes in physical
                  conditions. Corresponding models are called
                  multi-mode. We are interested in multi-domain,
                  component-oriented modeling as performed, for
                  example, with the modeling language Modelica that
                  leads naturally to Differential Algebraic Equations
                  (DAEs). This paper is thus about multi-mode DAE
                  systems. In particular, new methods are discussed to
                  overcome one key problem that was only solved for
                  specific subclasses of systems before: How to switch
                  from one mode to another one when the number of
                  equations may change and variables may exhibit
                  impulsive behavior? An evaluation is performed both
                  with the experimental modeling and simulation system
                  Modia, a domain specific language extension of the
                  programming language Julia, and with SunDAE, a novel
                  structural analysis library for multi-mode DAE
                  systems.}
}

@inproceedings{paper:arbor2019,
	Author = {N. A. {Akar} and B. {Cumming} and V. {Karakasis} and A. {K{\"u}sters} and W. {Klijn} and A. {Peyser} and S. {Yates}},
	Booktitle = {2019 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)},
	Doi = {10.1109/EMPDP.2019.8671560},
	Issn = {2377-5750},
	Month = {feb},
	Pages = {274--282},
	Title = {{Arbor --- A Morphologically-Detailed Neural Network Simulation Library for Contemporary High-Performance Computing Architectures}},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1109/EMPDP.2019.8671560}}

@article{Gewaltig:NEST,
	Author = {Marc-Oliver Gewaltig and Markus Diesmann},
	Journal = {Scholarpedia},
	Number = {4},
	Pages = {1430},
	Title = {NEST (NEural Simulation Tool)},
	Volume = {2},
	Year = {2007}}

@article{bell2004maximising,
	Author = {Bell, Anthony and Parra, Lucas},
	Journal = {Advances in neural information processing systems},
	Pages = {121--128},
	Title = {Maximising sensitivity in a spiking network},
	Volume = {17},
	Year = {2004}}

@article{gruebel:2020,
	Abstract = {This paper presents verification and implementation methods that have been developed for the design of the BrainScaleS-2 65 nm ASICs. The 2nd generation BrainScaleS chips are mixed-signal devices with tight coupling between full-custom analog neuromorphic circuits and two general purpose microprocessors (PPU) with SIMD extension for on-chip learning and plasticity. Simulation methods for automated analysis and pre-tapeout calibration of the highly parameterizable analog neuron and synapse circuits and for hardware-software co-development of the digital logic and software stack are presented. Accelerated operation of neuromorphic circuits and highly-parallel digital data buses between the full-custom neuromorphic part and the PPU require custom methodologies to close the digital signal timing at the interfaces. Novel extensions to the standard digital physical implementation design flow are highlighted. We present early results from the first full-size BrainScaleS-2 ASIC containing 512 neurons and 130 K synapses, demonstrating the successful application of these methods. An application example illustrates the full functionality of the BrainScaleS-2 hybrid plasticity architecture.},
	Author = {Gr{\"u}bl, Andreas and Billaudelle, Sebastian and Cramer, Benjamin and Karasenko, Vitali and Schemmel, Johannes},
	Da = {2020/11/01},
	Date-Added = {2020-11-28 15:56:35 +0100},
	Date-Modified = {2020-11-28 15:56:35 +0100},
	Doi = {10.1007/s11265-020-01558-7},
	Id = {Gr{\"u}bl2020},
	Isbn = {1939-8115},
	Journal = {Journal of Signal Processing Systems},
	Number = {11},
	Pages = {1277--1292},
	Title = {Verification and Design Methods for the BrainScaleS Neuromorphic Hardware System},
	Ty = {JOUR},
	Url = {https://doi.org/10.1007/s11265-020-01558-7},
	Volume = {92},
	Year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1007/s11265-020-01558-7}}

@misc{mueller2020extending,
	Archiveprefix = {arXiv},
	Author = {Eric M{\"u}ller and Christian Mauch and Philipp Spilger and Oliver Julien Breitwieser and Johann Kl{\"a}hn and David St{\"o}ckel and Timo Wunderlich and Johannes Schemmel},
	Eprint = {2003.13750},
	Primaryclass = {cs.NE},
	Title = {Extending BrainScaleS OS for BrainScaleS-2},
	Year = {2020}}

@misc{xiao:2017,
	Author = {Han Xiao and Kashif Rasul and Roland Vollgraf},
	Date = {2017-08-28},
	Eprint = {cs.LG/1708.07747},
	Eprintclass = {cs.LG},
	Eprinttype = {arXiv},
	Title = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
	Year = {2017}}

@article{Gronwall1919,
	Author = {T. H. Gronwall},
	Issn = {0003486X},
	Journal = {Annals of Mathematics},
	Number = {4},
	Pages = {292--296},
	Publisher = {Annals of Mathematics},
	Title = {Note on the Derivatives with Respect to a Parameter of the Solutions of a System of Differential Equations},
	Url = {http://www.jstor.org/stable/1967124},
	Volume = {20},
	Year = {1919},
	Bdsk-Url-1 = {http://www.jstor.org/stable/1967124}}

@article{joyal:1991geometry,
	Author = {Joyal, Andr{\'e} and Street, Ross},
	Journal = {Advances in mathematics},
	Number = {1},
	Pages = {55--112},
	Publisher = {Academic Press},
	Title = {The geometry of tensor calculus, I},
	Volume = {88},
	Year = {1991}}

@draft{joyal:1995geometry,
	Author = {Joyal, Andr{\'e} and Street, Ross},
	Title = {The geometry of tensor calculus II},
	Year = {1995}}

@article{chen:2018tvm,
	Author = {Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Shen, Haichen and Yan, Eddie Q and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
	Journal = {arXiv preprint arXiv:1802.04799},
	Pages = {1--15},
	Title = {TVM: end-to-end optimization stack for deep learning},
	Year = {2018}}

@article{kjolstad:2017tensor,
	Author = {Kjolstad, Fredrik and Kamil, Shoaib and Chou, Stephen and Lugato, David and Amarasinghe, Saman},
	Journal = {Proceedings of the ACM on Programming Languages},
	Number = {OOPSLA},
	Pages = {77},
	Publisher = {ACM},
	Title = {The tensor algebra compiler},
	Volume = {1},
	Year = {2017}}

@article{truong:2016latte,
	Author = {Truong, Leonard and Barik, Rajkishore and Totoni, Ehsan and Liu, Hai and Markley, Chick and Fox, Armando and Shpeisman, Tatiana},
	Journal = {ACM SIGPLAN Notices},
	Number = {6},
	Pages = {209--223},
	Publisher = {ACM},
	Title = {Latte: a language, compiler, and runtime for elegant and efficient deep neural networks},
	Volume = {51},
	Year = {2016}}

@inproceedings{amir:2013corelet,
	Author = {Amir, Arnon and Datta, Pallab and Risk, W.P. and Cassidy, Andrew and A. Kusnitz, Jeffrey and Esser, S.K. and Andreopoulos, Alexander and M. Wong, Theodore and Flickner, Myron and Alvarez-Icaza, Rodrigo and McQuinn, Emmett and Shaw, Ben and Pass, Norm and S. Modha, Dharmendra},
	Doi = {10.1109/IJCNN.2013.6707078},
	Journal = {Proceedings of the International Joint Conference on Neural Networks},
	Month = {08},
	Title = {Cognitive Computing Programming Paradigm: A Corelet Language for Composing Networks of Neurosynaptic Cores},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/IJCNN.2013.6707078}}

@inproceedings{roesch:2018relay,
	Author = {Roesch, Jared and Lyubomirsky, Steven and Weber, Logan and Pollock, Josh and Kirisame, Marisa and Chen, Tianqi and Tatlock, Zachary},
	Booktitle = {Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
	Organization = {ACM},
	Pages = {58--68},
	Title = {Relay: a new IR for machine learning frameworks},
	Year = {2018}}

@incollection{gibbons:2002calculating,
	Author = {Gibbons, Jeremy},
	Booktitle = {Algebraic and Coalgebraic Methods in the Mathematics of Program Construction},
	Pages = {151--203},
	Publisher = {Springer},
	Title = {Calculating functional programs},
	Year = {2002}}

@inproceedings{amir:2013diffsharp,
	Author = {Amir, Arnon and Datta, Pallab and Risk, W.P. and Cassidy, Andrew and A. Kusnitz, Jeffrey and Esser, S.K. and Andreopoulos, Alexander and M. Wong, Theodore and Flickner, Myron and Alvarez-Icaza, Rodrigo and McQuinn, Emmett and Shaw, Ben and Pass, Norm and S. Modha, Dharmendra},
	Doi = {10.1109/IJCNN.2013.6707078},
	Journal = {Proceedings of the International Joint Conference on Neural Networks},
	Month = {08},
	Title = {Cognitive Computing Programming Paradigm: A Corelet Language for Composing Networks of Neurosynaptic Cores},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/IJCNN.2013.6707078}}

@inproceedings{monti:2017geometric,
	Author = {Monti, Federico and Boscaini, Davide and Masci, Jonathan and Rodola, Emanuele and Svoboda, Jan and Bronstein, Michael M},
	Booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	Pages = {5115--5124},
	Title = {Geometric deep learning on graphs and manifolds using mixture model cnns},
	Year = {2017}}

@article{bronstein:2017geometric,
	Author = {Bronstein, Michael M and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre},
	Journal = {IEEE Signal Processing Magazine},
	Number = {4},
	Pages = {18--42},
	Publisher = {IEEE},
	Title = {Geometric deep learning: going beyond euclidean data},
	Volume = {34},
	Year = {2017}}

@inproceedings{arjovsky:2016unitary,
	Author = {Arjovsky, Martin and Shah, Amar and Bengio, Yoshua},
	Booktitle = {International Conference on Machine Learning},
	Pages = {1120--1128},
	Title = {Unitary evolution recurrent neural networks},
	Year = {2016}}

@article{paterson:2003,
	Author = {Paterson, Ross},
	Journal = {The Fun of Programming},
	Month = {01},
	Title = {Arrows and computation},
	Year = {2003}}

@article{courtney:2003,
	Author = {Courtney, Antony and Nilsson, Henrik and Peterson, John},
	Doi = {10.1145/871895.871897},
	Journal = {Proceedings of the 2003 ACM SIGPLAN Haskell Workshop},
	Month = {01},
	Title = {The Yampa Arcade},
	Year = {2003},
	Bdsk-Url-1 = {https://doi.org/10.1145/871895.871897}}

@inproceedings{elliot:1997,
	Author = {Conal Elliott and Paul Hudak},
	Booktitle = {International Conference on Functional Programming},
	Title = {Functional Reactive Animation},
	Url = {http://conal.net/papers/icfp97/},
	Year = 1997,
	Bdsk-Url-1 = {http://conal.net/papers/icfp97/}}

@article{mcbride:2001derivative,
	Author = {McBride, Conor},
	Journal = {Unpublished manuscript},
	Pages = {74--88},
	Publisher = {Citeseer},
	Title = {The derivative of a regular type is its type of one-hole contexts},
	Year = {2001}}

@article{huet:1997zipper,
	Author = {Huet, G{\'e}rard},
	Journal = {Journal of functional programming},
	Number = {5},
	Pages = {549--554},
	Publisher = {Cambridge University Press},
	Title = {The zipper},
	Volume = {7},
	Year = {1997}}

@inproceedings{elliott:2009beautiful,
	Author = {Elliott, Conal M},
	Booktitle = {ACM Sigplan Notices},
	Number = {9},
	Organization = {ACM},
	Pages = {191--202},
	Title = {Beautiful differentiation},
	Volume = {44},
	Year = {2009}}

@article{absil:2012projection,
	Author = {Absil, P-A and Malick, J{\'e}r{\^o}me},
	Journal = {SIAM Journal on Optimization},
	Number = {1},
	Pages = {135--158},
	Publisher = {SIAM},
	Title = {Projection-like retractions on matrix manifolds},
	Volume = {22},
	Year = {2012}}

@book{absil:2009optimization,
	Author = {Absil, P-A and Mahony, Robert and Sepulchre, Rodolphe},
	Publisher = {Princeton University Press},
	Title = {Optimization algorithms on matrix manifolds},
	Year = {2009}}

@article{adler:2002newton,
	Author = {Adler, Roy L and Dedieu, Jean-Pierre and Margulies, Joseph Y and Martens, Marco and Shub, Mike},
	Journal = {IMA Journal of Numerical Analysis},
	Number = {3},
	Pages = {359--390},
	Publisher = {Oxford University Press},
	Title = {Newton's method on Riemannian manifolds and a geometric model for the human spine},
	Volume = {22},
	Year = {2002}}

@article{jacobs2009:categorical,
	Author = {Jacobs, Bart and Heunen, Chris and Hasuo, Ichiro},
	Journal = {Journal of functional programming},
	Number = {3-4},
	Pages = {403--438},
	Publisher = {Cambridge University Press},
	Title = {Categorical semantics for arrows},
	Volume = {19},
	Year = {2009}}

@article{rivas2017:notions,
	Author = {Rivas, Exequiel and Jaskelioff, Mauro},
	Journal = {Journal of functional programming},
	Publisher = {Cambridge University Press},
	Title = {Notions of computation as monoids},
	Volume = {27},
	Year = {2017}}

@article{tambara:2006distributors,
	Author = {Tambara, Daisuke and others},
	Journal = {Hokkaido mathematical journal},
	Number = {2},
	Pages = {379--425},
	Publisher = {Hokkaido University, Department of Mathematics},
	Title = {Distributors on a tensor category},
	Volume = {35},
	Year = {2006}}

@article{pastro2008:doubles,
	Author = {Pastro, Craig and Street, Ross},
	Journal = {Theory and applications of categories},
	Number = {4},
	Pages = {61--75},
	Title = {Doubles for monoidal categories},
	Volume = {21},
	Year = {2008}}

@inproceedings{asada2010:arrows,
	Author = {Asada, Kazuyuki},
	Booktitle = {Proceedings of the third ACM SIGPLAN workshop on Mathematically Structured Functional Programming},
	Organization = {ACM},
	Pages = {33--42},
	Title = {Arrows are strong monads},
	Year = {2010}}

@article{uustalu:2005,
	Author = {Uustalu, Tarmo and Vene, Varmo},
	Journal = {J. UCS},
	Month = {01},
	Pages = {1310-1326},
	Title = {Signals and Comonads.},
	Volume = {11},
	Year = {2005}}

@article{halbwachs1991,
	Author = {Halbwachs, Nicholas and Caspi, Paul and Raymond, Pascal and Pilaud, Daniel},
	Journal = {Proceedings of the IEEE},
	Number = {9},
	Pages = {1305--1320},
	Publisher = {IEEE},
	Title = {The synchronous data flow programming language LUSTRE},
	Volume = {79},
	Year = {1991}}

@article{berry1992,
	Author = {Berry, G{\'e}rard and Gonthier, Georges},
	Journal = {Science of computer programming},
	Number = {2},
	Pages = {87--152},
	Publisher = {Elsevier},
	Title = {The Esterel synchronous programming language: Design, semantics, implementation},
	Volume = {19},
	Year = {1992}}

@book{halbwachs2013,
	Author = {Halbwachs, Nicolas},
	Publisher = {Springer Science \& Business Media},
	Title = {Synchronous programming of reactive systems},
	Volume = {215},
	Year = {2013}}

@article{maass1997networks,
	Author = {Maass, Wolfgang},
	Journal = {Neural networks},
	Number = {9},
	Pages = {1659--1671},
	Publisher = {Elsevier},
	Title = {Networks of spiking neurons: the third generation of neural network models},
	Volume = {10},
	Year = {1997}}

@article{jaderberg:2016,
	Archiveprefix = {arXiv},
	Author = {Max Jaderberg and Wojciech Marian Czarnecki and Simon Osindero and Oriol Vinyals and Alex Graves and Koray Kavukcuoglu},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/JaderbergCOVGK16},
	Eprint = {1608.05343},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:46:21 +0200},
	Title = {Decoupled Neural Interfaces using Synthetic Gradients},
	Url = {http://arxiv.org/abs/1608.05343},
	Volume = {abs/1608.05343},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1608.05343}}

@article{bellec:2019,
	Archiveprefix = {arXiv},
	Author = {Guillaume Bellec and Franz Scherr and Elias Hajek and Darjan Salaj and Robert A. Legenstein and Wolfgang Maass},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1901-09049},
	Eprint = {1901.09049},
	Journal = {CoRR},
	Timestamp = {Sat, 02 Feb 2019 16:56:00 +0100},
	Title = {Biologically inspired alternatives to backpropagation through time for learning in recurrent neural nets},
	Url = {http://arxiv.org/abs/1901.09049},
	Volume = {abs/1901.09049},
	Year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1901.09049}}

@article{rueckauer:2017,
	Author = {Rueckauer, Bodo and Lungu, Iulia-Alexandra and Hu, Yuhuang and Pfeiffer, Michael and Liu, Shih-Chii},
	Doi = {10.3389/fnins.2017.00682},
	Issn = {1662-453X},
	Journal = {Frontiers in Neuroscience},
	Pages = {682},
	Title = {{Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification}},
	Url = {https://www.frontiersin.org/article/10.3389/fnins.2017.00682},
	Volume = {11},
	Year = {2017},
	Bdsk-Url-1 = {https://www.frontiersin.org/article/10.3389/fnins.2017.00682},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnins.2017.00682}}

@article{werbos1990backpropagation,
	Author = {Werbos, Paul J and others},
	Journal = {Proceedings of the IEEE},
	Number = {10},
	Pages = {1550--1560},
	Title = {Backpropagation through time: what it does and how to do it},
	Volume = {78},
	Year = {1990}}

@techreport{robinson:utility,
	Added-At = {2008-03-11T14:52:34.000+0100},
	Address = {Cambridge, UK},
	Author = {Robinson, A. J. and Fallside, Frank},
	Biburl = {https://www.bibsonomy.org/bibtex/269a88ecbac9a51cbf0b4be189c412820/idsia},
	Citeulike-Article-Id = {2378809},
	Institution = {Engineering Department, Cambridge University},
	Interhash = {3c632364df265d7af795e2defe65894d},
	Intrahash = {69a88ecbac9a51cbf0b4be189c412820},
	Keywords = {nn},
	Number = {CUED/F-INFENG/TR.1},
	Priority = {2},
	Timestamp = {2008-03-11T14:59:56.000+0100},
	Title = {The Utility Driven Dynamic Error Propagation Network},
	Year = 1987}

@article{Bi1998,
	Author = {Bi, Guo-qiang and Poo, Mu-ming},
	Doi = {10.1523/JNEUROSCI.18-24-10464.1998},
	Eprint = {https://www.jneurosci.org/content/18/24/10464.full.pdf},
	Issn = {0270-6474},
	Journal = {Journal of Neuroscience},
	Number = {24},
	Pages = {10464--10472},
	Publisher = {Society for Neuroscience},
	Title = {Synaptic Modifications in Cultured Hippocampal Neurons: Dependence on Spike Timing, Synaptic Strength, and Postsynaptic Cell Type},
	Url = {https://www.jneurosci.org/content/18/24/10464},
	Volume = {18},
	Year = {1998},
	Bdsk-Url-1 = {https://www.jneurosci.org/content/18/24/10464},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.18-24-10464.1998}}

@phdthesis{zanasi:tel-01218015,
	Author = {Zanasi, Fabio},
	Hal_Id = {tel-01218015},
	Hal_Version = {v1},
	Keywords = {Frobenius algebra ; Hopf algebra ; Distributive law ; Control theory ; Category theory ; Semantics ; Linear algebra ; Signal flow graph ; Graphe de flots de signaux ; Alg{\`e}bre lin{\'e}aire ; Alg{\`e}bre de Frobenius ; Alg{\`e}bre de Hopf ; Loi distributive ; PROP ; S{\'e}mantique ; Th{\'e}orie des cat{\'e}gories ; Th{\'e}orie du contr{\^o}le},
	Month = Oct,
	Number = {2015ENSL1020},
	Pdf = {https://tel.archives-ouvertes.fr/tel-01218015/file/ZANASI_Fabio_2015ENSL1020_These.pdf},
	School = {{Ecole normale sup{\'e}rieure de lyon - ENS LYON}},
	Title = {{Interacting Hopf Algebras- the Theory of Linear Systems}},
	Type = {Theses},
	Url = {https://tel.archives-ouvertes.fr/tel-01218015},
	Year = {2015},
	Bdsk-Url-1 = {https://tel.archives-ouvertes.fr/tel-01218015}}

@article{selinger:2005,
	Abstract = {Dagger compact closed categories were recently introduced by Abramsky and Coecke, under the name ``strongly compact closed categories'', as an axiomatic framework for quantum mechanics. We present a graphical language for dagger compact closed categories, and sketch a proof of its completeness for equational reasoning. We give a general construction, the CPM construction, which associates to each dagger compact closed category its ``category of completely positive maps'', and we show that the resulting category is again dagger compact closed. We apply these ideas to Abramsky and Coecke's interpretation of quantum protocols, and to D'Hondt and Panangaden's predicate transformer semantics.},
	Author = {Selinger, Peter},
	File = {Selinger - Dagger compact closed categories and completely po.pdf:/home/jens/snap/zotero-snap/common/Zotero/storage/IVQGIWEM/Selinger - Dagger compact closed categories and completely po.pdf:application/pdf},
	Language = {en},
	Pages = {23},
	Title = {Dagger compact closed categories and completely positive maps (extended abstract)},
	Year = {2005}}

@article{fong:2019,
	Abstractnote = {Lenses are a well-established structure for modelling bidirectional transformations, such as the interactions between a database and a view of it. Lenses may be symmetric or asymmetric, and may be composed, forming the morphisms of a monoidal category. More recently, the notion of a learner has been proposed: these provide a compositional way of modelling supervised learning algorithms, and again form the morphisms of a monoidal category. In this paper, we show that the two concepts are tightly linked. We show both that there is a faithful, identity-on-objects symmetric monoidal functor embedding a category of asymmetric lenses into the category of learners, and furthermore there is such a functor embedding the category of learners into a category of symmetric lenses.},
	Author = {Fong, Brendan and Johnson, Michael},
	Journal = {arXiv:1903.03671 [cs, math]},
	Month = {May},
	Note = {arXiv: 1903.03671},
	Title = {Lenses and Learners},
	Year = {2019}}

@article{Kleisli:1965,
	Abstractnote = {Advancing research. Creating connections.},
	Author = {Kleisli, H.},
	Doi = {10.1090/S0002-9939-1965-0177024-4},
	Issn = {0002-9939, 1088-6826},
	Journal = {Proceedings of the American Mathematical Society},
	Number = {3},
	Pages = {544--546},
	Title = {Every standard construction is induced by a pair of adjoint functors},
	Volume = {16},
	Year = {1965},
	Bdsk-Url-1 = {https://doi.org/10.1090/S0002-9939-1965-0177024-4}}

@article{traub1991model,
	Author = {Traub, Roger D and Wong, Robert K and Miles, Richard and Michelson, Hillary},
	Journal = {Journal of neurophysiology},
	Number = {2},
	Pages = {635--650},
	Publisher = {American Physiological Society Bethesda, MD},
	Title = {A model of a CA3 hippocampal pyramidal neuron incorporating voltage-clamp data on intrinsic conductances},
	Volume = {66},
	Year = {1991}}

@article{ascoli2007neuromorpho,
	Author = {Ascoli, Giorgio A and Donohue, Duncan E and Halavi, Maryam},
	Journal = {Journal of Neuroscience},
	Number = {35},
	Pages = {9247--9251},
	Publisher = {Soc Neuroscience},
	Title = {NeuroMorpho. Org: a central resource for neuronal morphologies},
	Volume = {27},
	Year = {2007}}

@article{gidon2020dendritic,
	Author = {Gidon, Albert and Zolnik, Timothy Adam and Fidzinski, Pawel and Bolduan, Felix and Papoutsi, Athanasia and Poirazi, Panayiota and Holtkamp, Martin and Vida, Imre and Larkum, Matthew Evan},
	Journal = {Science},
	Number = {6473},
	Pages = {83--87},
	Publisher = {American Association for the Advancement of Science},
	Title = {Dendritic action potentials and computation in human layer 2/3 cortical neurons},
	Volume = {367},
	Year = {2020}}

@article{koch2016big,
	Author = {Koch, Christof and Jones, Allan},
	Journal = {Neuron},
	Number = {3},
	Pages = {612--616},
	Publisher = {Elsevier},
	Title = {Big science, team science, and open science for neuroscience},
	Volume = {92},
	Year = {2016}}

@misc{neuromorphoorg,
	Author = {Ascoli, Giorgio A and Donohue, Duncan E and Halavi, Maryam},
	Howpublished = {\url{http://neuromorpho.org}},
	Note = {Accessed: 2020-11-01},
	Title = {Neuromorpho.org}}

@article{zhang2017discrete,
	Author = {Zhang, Hong and Abhyankar, Shrirang and Constantinescu, Emil and Anitescu, Mihai},
	Journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
	Number = {5},
	Pages = {1247--1259},
	Publisher = {IEEE},
	Title = {Discrete adjoint sensitivity analysis of hybrid dynamical systems with switching},
	Volume = {64},
	Year = {2017}}

@article{zhang2019petsc,
	Author = {Zhang, Hong and Constantinescu, Emil M and Smith, Barry F},
	Journal = {arXiv preprint arXiv:1912.07696},
	Title = {PETSc TSAdjoint: a discrete adjoint ODE solver for first-order and second-order sensitivity analysis},
	Year = {2019}}

@incollection{baez2010rosetta_stone,
	Author = {Baez, John and Stay, Mike},
	Booktitle = {New structures for physics},
	Pages = {95--172},
	Publisher = {Springer},
	Title = {Physics, topology, logic and computation: a Rosetta Stone},
	Year = {2010}}

@article{lecun2015deep,
	Author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	Journal = {nature},
	Number = {7553},
	Pages = {436--444},
	Publisher = {Nature Publishing Group},
	Title = {Deep learning},
	Volume = {521},
	Year = {2015}}

@article{schmidhuber2015deep,
	Author = {Schmidhuber, J{\"u}rgen},
	Journal = {Neural networks},
	Pages = {85--117},
	Publisher = {Elsevier},
	Title = {Deep learning in neural networks: An overview},
	Volume = {61},
	Year = {2015}}

@incollection{turing2009computing,
	Author = {Turing, Alan M},
	Booktitle = {Parsing the turing test},
	Pages = {23--65},
	Publisher = {Springer},
	Title = {Computing machinery and intelligence},
	Year = {2009}}

@article{van_daalen:1996,
	Author = {van Daalen, Max and Shawe-Taylor, John and Zhao, Jieyu},
	Doi = {10.1016/0893-6080(96)00025-1},
	Issn = {0893-6080},
	Journal = {Neural networks : the official journal of the International Neural Network Society},
	Month = {August},
	Number = {6},
	Pages = {991---998},
	Title = {Learning in Stochastic Bit Stream Neural Networks},
	Url = {https://doi.org/10.1016/0893-6080(96)00025-1},
	Volume = {9},
	Year = {1996},
	Bdsk-Url-1 = {https://doi.org/10.1016/0893-6080(96)00025-1}}

@article{courbariaux:2016binarized,
	Author = {Courbariaux, Matthieu and Hubara, Itay and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
	Journal = {arXiv preprint arXiv:1602.02830},
	Title = {Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1},
	Year = {2016}}

@article{spinnaker:2014,
	Author = {S. B. {Furber} and F. {Galluppi} and S. {Temple} and L. A. {Plana}},
	Journal = {Proceedings of the IEEE},
	Number = {5},
	Pages = {652-665},
	Title = {The SpiNNaker Project},
	Volume = {102},
	Year = {2014}}

@inproceedings{shrestha:2018slayer,
	Author = {Shrestha, Sumit Bam and Orchard, Garrick},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {1412--1421},
	Title = {Slayer: Spike layer error reassignment in time},
	Year = {2018}}

@article{loihi:2018,
	Author = {M. {Davies} and N. {Srinivasa} and T. {Lin} and G. {Chinya} and Y. {Cao} and S. H. {Choday} and G. {Dimou} and P. {Joshi} and N. {Imam} and S. {Jain} and Y. {Liao} and C. {Lin} and A. {Lines} and R. {Liu} and D. {Mathaikutty} and S. {McCoy} and A. {Paul} and J. {Tse} and G. {Venkataramanan} and Y. {Weng} and A. {Wild} and Y. {Yang} and H. {Wang}},
	Journal = {IEEE Micro},
	Number = {1},
	Pages = {82-99},
	Title = {Loihi: A Neuromorphic Manycore Processor with On-Chip Learning},
	Volume = {38},
	Year = {2018}}

@article{bellec:2020solution,
	Author = {Bellec, Guillaume and Scherr, Franz and Subramoney, Anand and Hajek, Elias and Salaj, Darjan and Legenstein, Robert and Maass, Wolfgang},
	Journal = {bioRxiv},
	Pages = {738385},
	Publisher = {Cold Spring Harbor Laboratory},
	Title = {A solution to the learning dilemma for recurrent networks of spiking neurons},
	Year = {2020}}

@article{bellec:2019biologically,
	Author = {Bellec, Guillaume and Scherr, Franz and Hajek, Elias and Salaj, Darjan and Legenstein, Robert and Maass, Wolfgang},
	Journal = {arXiv preprint arXiv:1901.09049},
	Title = {Biologically inspired alternatives to backpropagation through time for learning in recurrent neural nets},
	Year = {2019}}

@article{urbanczik:2014learning,
	Author = {Urbanczik, Robert and Senn, Walter},
	Journal = {Neuron},
	Number = {3},
	Pages = {521--528},
	Publisher = {Elsevier},
	Title = {Learning by the dendritic prediction of somatic spiking},
	Volume = {81},
	Year = {2014}}

@inproceedings{bohte:2000spikeprop,
	Author = {Bohte, Sander M and Kok, Joost N and La Poutr{\'e}, Johannes A},
	Booktitle = {ESANN},
	Pages = {17--37},
	Title = {SpikeProp: backpropagation for networks of spiking neurons.},
	Volume = {48},
	Year = {2000}}

@unpublished{bradley:2019,
	Author = {Andrew M. Bradley},
	Title = {PDE-constrained optimization and the adjoint method},
	Year = {2019}}

@misc{lecun:2010,
	Author = {LeCun, Yann and Cortes, Corinna},
	Howpublished = {http://yann.lecun.com/exdb/mnist/},
	Title = {{MNIST} handwritten digit database},
	Url = {http://yann.lecun.com/exdb/mnist/},
	Year = 2010,
	Bdsk-Url-1 = {http://yann.lecun.com/exdb/mnist/}}

@inproceedings{chen:2018neural,
	Author = {Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
	Booktitle = {Advances in neural information processing systems},
	Pages = {6571--6583},
	Title = {Neural ordinary differential equations},
	Year = {2018}}

@inproceedings{jia:2019neural,
	Author = {Jia, Junteng and Benson, Austin R},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {9843--9854},
	Title = {Neural jump stochastic differential equations},
	Year = {2019}}

@incollection{dongsung:2018,
	Author = {Huh, Dongsung and Sejnowski, Terrence J},
	Booktitle = {Advances in Neural Information Processing Systems 31},
	Editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	Pages = {1433--1443},
	Publisher = {Curran Associates, Inc.},
	Title = {Gradient Descent for Spiking Neural Networks},
	Url = {http://papers.nips.cc/paper/7417-gradient-descent-for-spiking-neural-networks.pdf},
	Year = {2018},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/7417-gradient-descent-for-spiking-neural-networks.pdf}}

@inproceedings{ghica2007geometry,
	Author = {Ghica, Dan R},
	Booktitle = {Proceedings of the 34th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Pages = {363--375},
	Title = {Geometry of synthesis: a structured approach to VLSI design},
	Year = {2007}}

@article{zenke:2018,
	Author = {Zenke, Friedemann and Ganguli, Surya},
	Journal = {Neural computation},
	Number = {6},
	Pages = {1514--1541},
	Publisher = {MIT Press},
	Title = {Superspike: Supervised learning in multilayer spiking neural networks},
	Volume = {30},
	Year = {2018}}

@article{neftci:2019,
	Author = {Neftci, Emre O and Mostafa, Hesham and Zenke, Friedemann},
	Journal = {IEEE Signal Processing Magazine},
	Number = {6},
	Pages = {51--63},
	Publisher = {IEEE},
	Title = {Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to spiking neural networks},
	Volume = {36},
	Year = {2019}}

@article{krizhevsky:2009,
	Author = {Krizhevsky, Alex and Hinton, Geoffrey and others},
	Publisher = {Citeseer},
	Title = {Learning multiple layers of features from tiny images},
	Year = {2009}}

@article{rozenvasser:1967,
	Author = {Rozenvasser, EN},
	Journal = {Automatika i telemekhanika},
	Pages = {52--56},
	Title = {General sensitivity equations of discontinuous systems},
	Volume = {3},
	Year = {1967}}

@incollection{paszke:2019,
	Author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	Booktitle = {Advances in Neural Information Processing Systems 32},
	Editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. dAlche-Buc and E. Fox and R. Garnett},
	Pages = {8024--8035},
	Publisher = {Curran Associates, Inc.},
	Title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
	Url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
	Year = {2019},
	Bdsk-Url-1 = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}}

@article{corner:2020,
	Author = {Corner, Sebastien and Sandu, Adrian and Sandu, Corina},
	Journal = {Multibody System Dynamics},
	Pages = {1--26},
	Publisher = {Springer},
	Title = {Adjoint sensitivity analysis of hybrid multibody dynamical systems},
	Year = {2020}}

@article{aamir:2017,
	Author = {Aamir, SA and Stradmann, Y and M{\"u}ller, P and Pehle, Christian and Hartel, A and Gr{\"u}bl, A and Schemmel, J and Meier, K},
	Journal = {IEEE Transactions of Circuits and Systems-I},
	Title = {An accelerated LIF neuronal network array for a large scale neuromorphic system},
	Year = {2017}}

@mastersthesis{linnainmaa:1970,
	Author = {Linnainmaa, S.},
	School = {Univ. Helsinki},
	Title = {The representation of the cumulative rounding error of an algorithm as a {Taylor} expansion of the local rounding errors},
	Year = {1970}}

@article{romera2018vowel,
  title={Vowel recognition with four coupled spin-torque nano-oscillators},
  author={Romera, Miguel and Talatchian, Philippe and Tsunegi, Sumito and Araujo, Flavio Abreu and Cros, Vincent and Bortolotti, Paolo and Trastoy, Juan and Yakushiji, Kay and Fukushima, Akio and Kubota, Hitoshi and others},
  journal={Nature},
  volume={563},
  number={7730},
  pages={230--234},
  year={2018},
  publisher={Nature Publishing Group}
}

@incollection{rumelhart:86,
	Author = {D. E. Rumelhart and G. E. Hinton and R. J. Williams},
	Booktitle = {Parallel Distributed Processing},
	Editor = {D. E. Rumelhart and J. L. McClelland},
	Pages = {318-362},
	Publisher = {MIT Press},
	Title = {Learning Internal Representations by Error Propagation},
	Volume = {1},
	Year = {1986}}

@article{linnainmaa:1976,
	Author = {Linnainmaa, Seppo},
	Journal = {BIT Numerical Mathematics},
	Language = {English},
	Number = {2},
	Pages = {146-160},
	Publisher = {Kluwer Academic Publishers},
	Title = {Taylor expansion of the accumulated rounding error},
	Volume = {16},
	Year = {1976}}

@article{Markovic:2020,
	Author = {Markovi{\'c}, Danijela and Grollier, Julie},
	Doi = {10.1063/5.0020014},
	Issn = {1077-3118},
	Journal = {Applied Physics Letters},
	Month = {Oct},
	Number = {15},
	Pages = {150501},
	Publisher = {AIP Publishing},
	Title = {Quantum neuromorphic computing},
	Url = {http://dx.doi.org/10.1063/5.0020014},
	Volume = {117},
	Year = {2020},
	Bdsk-Url-1 = {http://dx.doi.org/10.1063/5.0020014}}

@article{pehle:2018,
	Author = {Pehle, Christian and Meier, Karlheinz and Oberthaler, Markus and Wetterich, Christof},
	Journal = {arXiv preprint arXiv:1810.10335},
	Title = {Emulating quantum computation with artificial neural networks},
	Year = {2018}}

@article{wunderlich2020eventprop,
	Author = {Wunderlich, Timo C and Pehle, Christian},
	Journal = {arXiv preprint arXiv:2009.08378},
	Title = {EventProp: Backpropagation for Exact Gradients in Spiking Neural Networks},
	Year = {2020}}

@article{aamir:2018,
	Author = {Aamir, Syed Ahmed and Stradmann, Yannik and M{\"u}ller, Paul and Pehle, Christian and Hartel, Andreas and Gr{\"u}bl, Andreas and Schemmel, Johannes and Meier, Karlheinz},
	Journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
	Number = {12},
	Pages = {4299--4312},
	Publisher = {IEEE},
	Title = {An accelerated lif neuronal network array for a large-scale mixed-signal neuromorphic architecture},
	Volume = {65},
	Year = {2018}}

@misc{spilger2020hxtorch,
	Archiveprefix = {arXiv},
	Author = {Philipp Spilger and Eric M{\"u}ller and Arne Emmel and Aron Leibfried and Christian Mauch and Christian Pehle and Johannes Weis and Oliver Breitwieser and Sebastian Billaudelle and Sebastian Schmitt and Timo C. Wunderlich and Yannik Stradmann and Johannes Schemmel},
	Eprint = {2006.13138},
	Primaryclass = {cs.NE},
	Title = {hxtorch: PyTorch for BrainScaleS-2 -- Perceptrons on Analog Neuromorphic Hardware},
	Year = {2020}}

@misc{pehle2020neuromorphic,
	Archiveprefix = {arXiv},
	Author = {Christian Pehle and Christof Wetterich},
	Eprint = {2005.01533},
	Primaryclass = {cond-mat.dis-nn},
	Title = {Neuromorphic quantum computing},
	Year = {2020}}

@article{rotter1999exact,
	Author = {Rotter, Stefan and Diesmann, Markus},
	Journal = {Biological cybernetics},
	Number = {5-6},
	Pages = {381--402},
	Publisher = {Springer},
	Title = {Exact digital simulation of time-invariant linear systems with applications to neuronal modeling},
	Volume = {81},
	Year = {1999}}

@article{schultz2020dynamical,
  title={Dynamical systems and sheaves},
  author={Schultz, Patrick and Spivak, David I and Vasilakopoulou, Christina},
  journal={Applied Categorical Structures},
  volume={28},
  number={1},
  pages={1--57},
  year={2020},
  publisher={Springer}
}

@article{nadasdy1999replay,
  title={Replay and time compression of recurring spike sequences in the hippocampus},
  author={N{\'a}dasdy, Zolt{\'a}n and Hirase, Hajime and Czurk{\'o}, Andr{\'a}s and Csicsvari, Jozsef and Buzs{\'a}ki, Gy{\"o}rgy},
  journal={Journal of Neuroscience},
  volume={19},
  number={21},
  pages={9497--9507},
  year={1999},
  publisher={Soc Neuroscience}
}

@article{louie2001temporally,
  title={Temporally structured replay of awake hippocampal ensemble activity during rapid eye movement sleep},
  author={Louie, Kenway and Wilson, Matthew A},
  journal={Neuron},
  volume={29},
  number={1},
  pages={145--156},
  year={2001},
  publisher={Elsevier}
}

@article{bukalo2013synaptic,
  title={Synaptic plasticity by antidromic firing during hippocampal network oscillations},
  author={Bukalo, Olena and Campanac, Emilie and Hoffman, Dax A and Fields, R Douglas},
  journal={Proceedings of the National Academy of Sciences},
  volume={110},
  number={13},
  pages={5175--5180},
  year={2013},
  publisher={National Acad Sciences}
}

@article{bahner2011cellular,
  title={Cellular correlate of assembly formation in oscillating hippocampal networks in vitro},
  author={B{\"a}hner, Florian and Weiss, Elisa K and Birke, Gunnar and Maier, Nikolaus and Schmitz, Dietmar and Rudolph, Uwe and Frotscher, Michael and Traub, Roger D and Both, Martin and Draguhn, Andreas},
  journal={Proceedings of the National Academy of Sciences},
  volume={108},
  number={35},
  pages={E607--E616},
  year={2011},
  publisher={National Acad Sciences}
}

@article{papatheodoropoulos2008possible,
  title={A possible role of ectopic action potentials in the in vitro hippocampal sharp wave--ripple complexes},
  author={Papatheodoropoulos, C},
  journal={Neuroscience},
  volume={157},
  number={3},
  pages={495--501},
  year={2008},
  publisher={Elsevier}
}

@article{leung2006gabab,
  title={GABAB receptors inhibit backpropagating dendritic spikes in hippocampal CA1 pyramidal cells in vivo},
  author={Leung, L Stan and Peloquin, Pascal},
  journal={Hippocampus},
  volume={16},
  number={4},
  pages={388--407},
  year={2006},
  publisher={Wiley Online Library}
}

@article{traub1999high,
  title={High-frequency population oscillations are predicted to occur in hippocampal pyramidal neuronal networks interconnected by axoaxonal gap junctions},
  author={Traub, Roger D and Schmitz, D and Jefferys, John GR and Draguhn, A},
  journal={Neuroscience},
  volume={92},
  number={2},
  pages={407--426},
  year={1999},
  publisher={Elsevier}
}

@article{mateus2021vitro,
  title={In vitro neuronal networks show bidirectional axonal conduction with antidromic action potentials effectively depolarizing the soma},
  author={Mateus, Jose and Lopes, Catia and Aroso, Miguel and Costa, Ana and Geros, Ana and Pereira, Antonio and Meneses, Joao and Faria, Paula and Neto, Estrela and Lamghari, Meriem and others},
  journal={bioRxiv},
  year={2021},
  publisher={Cold Spring Harbor Laboratory}
}

@article{magnusson2008retrograde,
  title={Retrograde GABA signaling adjusts sound localization by balancing excitation and inhibition in the brainstem},
  author={Magnusson, Anna K and Park, Thomas J and Pecka, Michael and Grothe, Benedikt and Koch, Ursula},
  journal={Neuron},
  volume={59},
  number={1},
  pages={125--137},
  year={2008},
  publisher={Elsevier}
}

@incollection{zilberter2005classical,
  title={Classical Neurotransmitters as Retrograde Messengers in Layer 2/3 of the Neocortex: Emphasis on Glutamate and Gaba},
  author={Zilberter, Yuri and Harkany, Tibor},
  booktitle={Dendritic Neurotransmitter Release},
  pages={117--131},
  year={2005},
  publisher={Springer}
}


@article{regehr2009activity,
  title={Activity-dependent regulation of synapses by retrograde messengers},
  author={Regehr, Wade G and Carey, Megan R and Best, Aaron R},
  journal={Neuron},
  volume={63},
  number={2},
  pages={154--170},
  year={2009},
  publisher={Elsevier}
}

@article{diba2007forward,
  title={Forward and reverse hippocampal place-cell sequences during ripples},
  author={Diba, Kamran and Buzs{\'a}ki, Gy{\"o}rgy},
  journal={Nature neuroscience},
  volume={10},
  number={10},
  pages={1241--1242},
  year={2007},
  publisher={Nature Publishing Group}
}

@article{igata2021prioritized,
  title={Prioritized experience replays on a hippocampal predictive map for learning},
  author={Igata, Hideyoshi and Ikegaya, Yuji and Sasaki, Takuya},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={1},
  year={2021},
  publisher={National Acad Sciences}
}

@article{karlsson2009awake,
  title={Awake replay of remote experiences in the hippocampus},
  author={Karlsson, Mattias P and Frank, Loren M},
  journal={Nature neuroscience},
  volume={12},
  number={7},
  pages={913--918},
  year={2009},
  publisher={Nature Publishing Group}
}

@article{pinault1995backpropagation,
  title={Backpropagation of action potentials generated at ectopic axonal loci: hypothesis that axon terminals integrate local environmental signals},
  author={Pinault, Didier},
  journal={Brain Research Reviews},
  volume={21},
  number={1},
  pages={42--92},
  year={1995},
  publisher={Elsevier}
}

@book{feyerabend1975against,
  title={Against method},
  author={Feyerabend, Paul},
  year={1975},
  publisher={New Left Books}
}

@book{feyerabend1973science,
  title={Science in a Free Society},
  author={Feyerabend, Paul},
  year={1973},
  publisher={Schocken Books}
}

@article{pehle2020neuromorphic,
  title = {Neuromorphic quantum computing},
  author = {\textbf{Christian Pehle} and Wetterich, Christof},
  journal = {Phys. Rev. E},
  volume = {106},
  issue = {4},
  pages = {045311},
  numpages = {12},
  year = {2022},
  month = {},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.106.045311},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.106.045311}
}

@article{pehle2022eventbased,
  title = {Event-based Backpropagation for Analog Neuromorphic Hardware},
  author = {\textbf{Christian Pehle} and Blessing, Luca and Arnold, Elias and M{\"u}ller, Eric and Schemmel, Johannes},
  journal = {In preparation},
  year = {2022}  
}

@article{bies2014chow,
  title={{Chow} groups, {Deligne} cohomology and massless matter in {F-theory}},
  author={Bies, Martin and Mayrhofer, Christoph and \textbf{Christian Pehle} and Weigand, Timo},
  journal={arXiv preprint arXiv:1402.5144},
  year={2014}
}

@article{spilger2020hxtorch,
  title={hxtorch: {PyTorch} for {ANNs} on {BrainScaleS-2}},
  author={Spilger, Philipp and M{\"u}ller, Eric and Emmel, Arne and Leibfried, Aron and Mauch, Christian and \textbf{Christian Pehle} and Weis, Johannes and Breitwieser, Oliver and Billaudelle, Sebastian and Schmitt, Sebastian and others},
  journal={arXiv:2006.13138},
  year={2020}
}

@article{wunderlich2019demonstrating,
  title={Demonstrating advantages of neuromorphic computation: a pilot study},
  author={Wunderlich, Timo and Kungl, Akos F and M{\"u}ller, Eric and Hartel, Andreas and Stradmann, Yannik and Aamir, Syed Ahmed and Gr{\"u}bl, Andreas and Heimbrecht, Arthur and Schreiber, Korbinian and St{\"o}ckel, David and \textbf{Christian Pehle} and others},
  journal={Frontiers in neuroscience},
  volume={13},
  pages={260},
  year={2019},
  publisher={Frontiers}
}

@article{billaudelle2019versatile,
  title={Versatile emulation of spiking neural networks on an accelerated neuromorphic substrate},
  author={Billaudelle, Sebastian and Stradmann, Yannik and Schreiber, Korbinian and Cramer, Benjamin and Baumbach, Andreas and Dold, Dominik and G{\"o}ltz, Julian and Kungl, Akos F and Wunderlich, Timo C and Hartel, Andreas and others},
  journal={arXiv:1912.12980},
  year={2019}
}

@article{wunderlich2020eventprop,
	Author = {Wunderlich, Timo C and \textbf{Christian Pehle}},
	Journal = {arXiv:2009.08378},
	Title = {EventProp: Backpropagation for Exact Gradients in Spiking Neural Networks},
	Year = {2020}}


@inproceedings{schreiber2020closed, author = {Schreiber, K. and Wunderlich, T. C. and \textbf{C. Pehle} and Petrovici, M. A. and Schemmel, J. and Meier, K.}, title = {Closed-Loop Experiments on the BrainScaleS-2 Architecture}, year = {2020}, isbn = {9781450377188}, publisher = {Association for Computing Machinery}, url = {https://doi.org/10.1145/3381755.3381776}, doi = {10.1145/3381755.3381776}, abstract = {The evolution of biological brains has always been contingent on their embodiment within their respective environments, in which survival required appropriate navigation and manipulation skills. Studying such interactions thus represents an important aspect of computational neuroscience and, by extension, a topic of interest for neuromorphic engineering. Here, we present three examples of embodiment on the BrainScaleS-2 architecture, in which dynamical timescales of both agents and environment are accelerated by several orders of magnitude with respect to their biological archetypes.}, booktitle = {Proceedings of the Neuro-Inspired Computational Elements Workshop}, articleno = {17}, numpages = {3}, keywords = {neuromorphic hardware, Closed-loop, path integration, neurorobotics, reinforcement learning}, location = {Heidelberg, Germany}, series = {NICE '20} }

@article{pehle2018emulating,
  title={Emulating quantum computation with artificial neural networks},
  author={\textbf{Christian Pehle} and Meier, Karlheinz and Oberthaler, Markus and Wetterich, Christof},
  journal={arXiv:1810.10335},
  year={2018}
}

@article{aamir2018accelerated,
  title={An accelerated lif neuronal network array for a large-scale mixed-signal neuromorphic architecture},
  author={Aamir, Syed Ahmed and Stradmann, Yannik and M{\"u}ller, Paul and \textbf{Christian Pehle} and Hartel, Andreas and Gr{\"u}bl, Andreas and Schemmel, Johannes and Meier, Karlheinz},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers},
  volume={65},
  number={12},
  pages={4299--4312},
  year={2018},
  publisher={IEEE}
}

@article{bohnstingl2019neuromorphic,
  title={Neuromorphic hardware learns to learn},
  author={Bohnstingl, Thomas and Scherr, Franz and \textbf{Christian Pehle} and Meier, Karlheinz and Maass, Wolfgang},
  journal={Frontiers in neuroscience},
  volume={13},
  pages={483},
  year={2019},
  publisher={Frontiers}
}

@article{cramer2020training,
  title={Training spiking multi-layer networks with surrogate gradients on an analog neuromorphic substrate},
  author={Cramer, Benjamin and Billaudelle, Sebastian and Kanya, Simeon and Leibfried, Aron and Gr{\"u}bl, Andreas and Karasenko, Vitali and \textbf{Christian Pehle} and Schreiber, Korbinian and Stradmann, Yannik and Weis, Johannes and others},
  journal={arXiv:2006.07239},
  year={2020}
}

@article{wunderlich2021event,
  title={Event-based backpropagation can compute exact gradients for spiking neural networks},
  author={Wunderlich, Timo C and \textbf{Christian Pehle}},
  journal={Scientific Reports},
  volume={11},
  number={1},
  pages={1--17},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{cramer2022surrogate,
  title={Surrogate gradients for analog neuromorphic computing},
  author={Cramer, Benjamin and Billaudelle, Sebastian and Kanya, Simeon and Leibfried, Aron and Gr{\"u}bl, Andreas and Karasenko, Vitali and \textbf{Christian Pehle} and Schreiber, Korbinian and Stradmann, Yannik and Weis, Johannes and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={119},
  number={4},
  pages={e2109194119},
  year={2022},
  publisher={National Acad Sciences}
}

@article{pehle2022brainscales,
  title={The {BrainScaleS-2} accelerated neuromorphic system with hybrid plasticity},
  author={\textbf{Christian Pehle} and Billaudelle, Sebastian and Cramer, Benjamin and Kaiser, Jakob and Schreiber, Korbinian and Stradmann, Yannik and Weis, Johannes and Leibfried, Aron and M{\"u}ller, Eric and Schemmel, Johannes},
  journal={Frontiers in Neuroscience},
  volume={16},
  year={2022},
  publisher={Frontiers Media SA}
}


@software{norse2021,
  author       = {\textbf{Christian Pehle} and
                  Pedersen, Jens Egholm},
  title        = {{Norse -  A deep learning library for spiking 
                   neural networks}},
  year         = 2021
}

@article{williams1989experimental,
  title={Experimental analysis of the real-time recurrent learning algorithm},
  author={Williams, Ronald J and Zipser, David},
  journal={Connection science},
  volume={1},
  number={1},
  pages={87--111},
  year={1989},
  publisher={Taylor \& Francis}
}

@phdthesis{pehle2021adjoint,
  title={Adjoint equations of spiking neural networks},
  author={Pehle, Christian-Gernot},
  year={2021}
}

@phdthesis{friedmann2013new,
  title={A new approach to learning in neuromorphic hardware},
  author={Friedmann, Simon},
  year={2013}
}

@article{friedmann2016demonstrating,
  title={Demonstrating hybrid learning in a flexible neuromorphic hardware system},
  author={Friedmann, Simon and Schemmel, Johannes and Gr{\"u}bl, Andreas and Hartel, Andreas and Hock, Matthias and Meier, Karlheinz},
  journal={IEEE transactions on biomedical circuits and systems},
  volume={11},
  number={1},
  pages={128--142},
  year={2016},
  publisher={IEEE}
}

@article{zador2022toward,
  title={Toward next-generation artificial intelligence: Catalyzing the neuroai revolution},
  author={Zador, Anthony and Richards, Blake and {\"O}lveczky, Bence and Escola, Sean and Bengio, Yoshua and Boahen, Kwabena and Botvinick, Matthew and Chklovskii, Dmitri and Churchland, Anne and Clopath, Claudia and others},
  journal={arXiv preprint arXiv:2210.08340},
  year={2022}
}